# 媒体与认知 — 复习与讨论讲义（详细版）

## 14.pdf 第 1 页（Review and Discussion - 复习与讨论）

媒体与认知（Media and Cognition）

讲座 14：复习与讨论（Review and Discussion）

清华大学电子工程系（Dept. of EE, Tsinghua University）

方璐（Lu FANG）

------

## 14.pdf 第 2 页（Quick Review - 快速复习）

### 媒体与信息（Media and Information）

- **核心定义**：媒体是信息的载体（Media is the Information Carrier），不同类型的媒体通过特定符号系统传递信息，其发展历程体现了信息传播效率的逐步提升。
- **媒体类型演进**：
  1. **符号语言（Symbol Language）**：最基础的信息传递形式，通过约定俗成的符号（如文字符号、手势符号）表达含义，是后续所有媒体形式的基础。
  2. **文本（Text）**：将符号语言规范化、结构化后的载体，如书籍、文章，实现信息的长期存储和跨时空传播。
  3. **印刷品（Press）**：以印刷技术为核心的媒体形式，如报纸、杂志，大幅降低信息传播成本，扩大信息覆盖范围。
  4. **电子媒体（Electronic）**：依托电子技术的媒体，如广播、电视，实现声音和动态图像的实时传播，打破空间限制。
  5. **数字媒体（Digital）**：以数字信号为基础的媒体形式，如互联网内容、数字视频，具备可编辑、可复制、可交互等特性，是当前主流媒体形态。

### 数字媒体与媒体转换（Digital Media & Media Translation）

- **数字媒体（Digital Media）**：所有以数字形式存在的媒体内容，涵盖文本、图像、音频、视频等多种类型，其核心优势是便于计算机处理、存储和传输。
- **媒体转换（Media Translation）**：将一种媒体形式转换为另一种媒体形式的技术，**机器翻译（Machine translation）** 是典型应用，例如文本与语音、图像与文字之间的转换。

### 媒体类型与对应示例（Media Types and Examples）

| 媒体类型（Media Type） | 示例（Examples）                                             |
| ---------------------- | ------------------------------------------------------------ |
| 文本（Text）           | 汉字（Chinese Characters）、英文（English）等语言文字        |
| 图像（Image）          | 照片（Photos）、插画（Illustrations）、截图（Screenshots）   |
| 视频（Video）          | 电影（Movies）、短视频（Short Videos）、监控录像（Surveillance Videos） |
| 图形（Graphic）        | 图表（Charts）、示意图（Schematic Diagrams）、图标（Icons）  |
| 动画（Animation）      | 卡通动画（Cartoon Animations）、3D 动画（3D Animations）、动态表情包（Animated Stickers） |
| 音频（Audio）          | 音乐（Music）、语音（Speech）、环境音效（Environmental Sounds） |

------

## 14.pdf 第 3 页（Media Processing Technologies - 媒体处理技术）

### 跨媒体处理技术（Cross-Media Processing Technologies）

不同类型媒体之间可通过特定技术实现转换与协同处理，核心技术及应用场景如下：

- **文本与音频交互（Text-Audio Interaction）**
  1. **语音识别（Speech recognition）**：将音频形式的语音转换为文本，如手机语音输入、会议实时转写，核心是提取语音信号中的特征（如频谱、音素），匹配文本词汇。
  2. **语音合成（Audio synthesis）**：将文本转换为自然语音，如语音助手播报、有声书生成，通过构建语音模型，模拟人类发声规律。
  3. **同声传译（Simultaneous interpretation）**：实时将一种语言的语音转换为另一种语言的语音，结合语音识别、机器翻译和语音合成技术，广泛应用于国际会议。
- **文本与图像交互（Text-Image Interaction）**
  1. **图像描述（Image caption）**：为图像生成文字描述，如自动为照片添加 “小狗在草地上奔跑” 的 caption，需理解图像内容和语义关系。
  2. **图像生成（Image generation）**：根据文本指令生成对应图像，如输入 “蓝色天空下的白色城堡” 生成符合描述的图像，典型模型有 DALL-E、MidJourney。
- **图像与音频交互（Image-Audio Interaction）**
  1. **图像引导音频合成（Image guided audio synthesis）**：根据图像内容生成匹配的音频，如为风景图像生成鸟鸣、风声等环境音效，需建立图像场景与音频特征的关联。
  2. **音频引导图像生成（Audio guided image generation）**：根据音频内容生成对应图像，如根据音乐节奏和风格生成抽象艺术图像，捕捉音频的情感和韵律特征。
- **图像风格转换（Style transfer）**：将一幅图像的风格迁移到另一幅图像上，如将普通照片转换为梵高油画风格，核心是分离图像的内容特征和风格特征，再重新组合。

------

## 14.pdf 第 4 页（Relationship Between Media and Cognition - 媒体与认知的关系）

### 认知维度（Cognition Dimensions）

认知是人类通过感官获取信息并进行处理的过程，主要包括以下感官维度：

- **视觉（Visual sense）**：通过眼睛获取图像信息，是人类最主要的信息来源，对应处理图像、视频、图形等视觉媒体。
- **听觉（Auditory sense）**：通过耳朵获取声音信息，处理音频、语音等听觉媒体。
- **超听觉（Hyper-aural sense）**：超越人类正常听觉范围的感知，如对次声波（Subsonic）、超声波（Ultrasound）的感知，对应特殊音频媒体处理。
- **超视觉（Hyper-vision）**：超越人类正常视觉范围的感知，如对红外线（Infrared）、紫外线（UV）的感知，对应特殊图像媒体（如红外成像）处理。
- **其他感官（Other senses）**：如触觉（Touch）、嗅觉（Olfaction）、味觉（Gustation），当前媒体技术对这些感官的模拟仍在发展中（如 VR 触觉反馈）。

### 媒体维度（Media Dimensions）

媒体根据认知维度和表现形式，可分为以下类别：

- **静态媒体（Static Media）**：内容不随时间变化的媒体，如文本（Text）、图像（Image）、图形（Graph），主要对应视觉认知。
- **动态媒体（Dynamic Media）**：内容随时间变化的媒体，如动画（Animation）、视频（Video），结合视觉和时间维度，传递动态信息。
- **听觉媒体（Aural Media）**：
  - **规则听觉媒体**：如语音（Voice）、音乐（Music），具有明确的结构和规律。
  - **不规则听觉媒体**：如环境音效（Sound），无固定结构，用于还原场景氛围。
- **超感知媒体（Hyper-sensory Media）**：对应超听觉和超视觉认知，如红外图像、超声波音频，用于特殊场景（如医疗检测、安防监控）。

### 媒体与认知的核心作用（Core Roles of Media & Cognition）

1. **拓展认知能力（Expand cognitive ability）**：媒体作为信息载体，帮助人类突破自身感官局限，例如通过望远镜图像观察宇宙（拓展视觉范围）、通过历史文献了解过去（拓展时间范围）。
2. **创造新型媒体（Create new media）**：认知需求推动媒体技术创新，例如为满足沉浸式体验需求，开发出 VR（虚拟现实）、AR（增强现实）等新型媒体。
3. **赋能机器智能（Empower machine intelligence）**：通过模拟人类认知过程（如视觉识别、语音理解），让机器具备处理和理解媒体信息的能力，是人工智能的核心研究方向。

------

## 14.pdf 第 5 页（Foundations of Artificial Intelligence - 人工智能基础）

### 人工智能的起源（Origin of Artificial Intelligence）

- **达特茅斯夏季人工智能研究项目（Dartmouth Summer Research Project on AI）**：1956 年，约翰・麦卡锡（John McCarthy）等科学家在达特茅斯学院举办该项目，首次提出 “人工智能（Artificial Intelligence, AI）” 概念，标志着人工智能学科的诞生。该项目明确了 AI 的研究目标：让机器模拟人类的学习、推理、决策等智能行为。

### 人工智能的主要流派（Main Genres of Artificial Intelligence）

人工智能发展过程中，形成了三种核心研究范式，分别从不同角度模拟智能：

| 流派（Genre）             | 核心思想（Core Idea）                                        | 关键技术（Key Technologies）                                 | 应用场景（Application Scenarios）                            |
| ------------------------- | ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 符号主义（Symbolism）     | 认为智能的核心是符号推理，通过定义规则和逻辑来模拟人类思维，如 “if-then” 规则推理 | 逻辑推理（Logical Reasoning）、专家系统（Expert Systems）、知识图谱（Knowledge Graphs） | 医疗诊断（如疾病诊断专家系统）、法律推理、数学定理证明       |
| 联结主义（Connectionism） | 认为智能源于大脑神经元的连接，通过模拟神经网络的结构和功能实现智能 | 人工神经网络（Artificial Neural Networks）、深度学习（Deep Learning）、卷积神经网络（CNNs） | 图像识别（如人脸识别）、语音处理（如语音助手）、自然语言处理（如机器翻译） |
| 行为主义（Behaviorism）   | 认为智能源于对环境的感知和行为反馈，通过 “感知 - 行动” 循环学习，无需内部符号表示 | 强化学习（Reinforcement Learning）、机器人学（Robotics）、控制论（Cybernetics） | 机器人控制（如自动驾驶）、游戏 AI（如 AlphaGo）、工业自动化  |

### 图灵测试（Turing Test）

- **提出者**：艾伦・图灵（Alan Turing），1950 年在论文《计算机器与智能》中提出。
- **核心思想**：通过让人类测试者与机器、人类进行匿名对话（如文字聊天），若测试者无法区分对话对象是机器还是人类，则认为机器通过图灵测试，具备 “智能”。
- **意义**：图灵测试是人工智能领域最早的智能评估标准，虽存在局限性（如未考虑机器的 “理解” 能力），但为 AI 研究提供了明确的目标方向。

------

## 14.pdf 第 6 页（Feature Engineering I: PCA - 特征工程 I：主成分分析）

### PCA 的核心目标（Core Goal of PCA）

- **问题**：高维数据存在冗余和噪声，如何在保留关键信息的前提下降低维度？
- **答案**：主成分分析（Principal Component Analysis, PCA）是一种无监督降维技术，核心是**最大化数据投影后的方差（Maximizing the variance）**—— 方差越大，说明投影后的数据保留原始数据的差异信息越多。

### PCA 原理示例（PCA Principle Example）

假设有一组 3D 数据点（p1, p2, p3），在特定坐标系下，每个点仅有一个非零坐标（如所有点都分布在一条直线上）：

- **原始存储**：需存储每个点的 3 个坐标（如 3 字节 / 点 ×6 点 = 18 字节）。
- **PCA 压缩存储**：只需存储直线方向（3 字节，即主成分方向）和每个点在该直线上的非零坐标（1 字节 / 点 ×6 点 = 6 字节），总存储量 9 字节，节省 50% 空间。

### 如何判断数据能否压缩？（How to Determine Data Compressibility?）

- **核心依据**：数据点之间的**相关性（Correlation）**—— 若数据点高度相关（如分布在一条直线或一个平面上），则存在冗余，可通过 PCA 压缩。
- **PCA 实现步骤**：
  1. 计算数据的**协方差矩阵（Covariance Matrix）**：衡量不同维度数据之间的相关性。
  2. 求解协方差矩阵的**特征值（Eigenvalues）和特征向量（Eigenvectors）**：特征值越大，对应特征向量的方向（主成分）包含的数据差异信息越多。
  3. 选择**特征值最大的前 k 个特征向量**作为主成分，将数据投影到这些主成分构成的低维子空间（Orthogonal Subspace），实现降维。

### PCA 方差贡献率示例（PCA Variance Contribution Example）

（图中为 PCA 各主成分（PC1~PC10）的方差贡献率折线图，纵轴为方差贡献率（%），范围 0~25%）

- **观察**：PC1 的方差贡献率最高（约 22%），PC2 次之（约 18%），后续 PC 的方差贡献率逐渐降低，PC7 后接近 0。
- **结论**：只需选择前 2~3 个主成分，即可保留原始数据约 40%~50% 的方差（关键信息），大幅降低维度。

------

## 14.pdf 第 7 页（Feature Engineering I: Harris Corner Detection - 特征工程 I：Harris 角点检测）

### 角点检测的核心依据（Core Basis of Corner Detection）

图像中的区域根据灰度变化模式，可分为三类，角点的核心特征是**全方向灰度显著变化**：

1. **平坦区域（Flat Region）**：所有方向移动窗口（局部图像块），灰度均无明显变化（如纯色墙面），无关键特征。
2. **边缘区域（Edge Region）**：沿边缘方向移动窗口，灰度无变化；垂直于边缘方向移动，灰度变化显著（如物体轮廓线），仅包含单向特征。
3. **角点区域（Corner Region）**：所有方向移动窗口，灰度均发生显著变化（如物体的拐角、交叉点），是图像中最具辨识度的特征点。

### Harris 角点检测公式（Harris Corner Detection Formulas）

#### 1. 协方差矩阵 M（Covariance Matrix M）

对于图像局部区域，计算 X、Y 方向梯度（Iₓ、Iᵧ），构建协方差矩阵 M：

\(M = \begin{bmatrix} \sum I_x^2 & \sum I_x I_y \\ \sum I_x I_y & \sum I_y^2 \end{bmatrix}\)

其中，\(\sum I_x^2\) 是 X 方向梯度的平方和，\(\sum I_y^2\) 是 Y 方向梯度的平方和，\(\sum I_x I_y\) 是 X、Y 方向梯度的乘积和，这些求和均在局部窗口内进行。

#### 2. 角点响应函数 R（Corner Response Function）

通过矩阵 M 的行列式（det (M)）和迹（trace (M)）定义角点响应值 R，用于判断区域类型：

\(R = \det(M) - \kappa \cdot trace^2(M)\)

其中：

- **行列式 det (M)**：反映两个特征值的乘积，\(\det(M) = \lambda_1 \cdot \lambda_2\)（\(\lambda_1、\lambda_2\) 是 M 的特征值）。
- **迹 trace (M)**：反映两个特征值的和，\(trace(M) = \lambda_1 + \lambda_2\)。
- **κ**：经验常数，通常取值 0.04~0.06，用于调整响应函数的灵敏度。

#### 3. 区域类型判断规则（Region Type Judgment Rules）

- **平坦区域**：\(\lambda_1 \approx 0\) 且 \(\lambda_2 \approx 0\) → \(R \approx 0\)。
- **边缘区域**：一个特征值远大于 0，另一个接近 0 → \(R < 0\)。
- **角点区域**：两个特征值均远大于 0 → \(R > 0\)（且 R 值越大，角点特征越显著）。

### Harris 角点检测器的特性（Properties of Harris Corner Detector）

- **旋转不变性（Rotation Invariance）**：是。图像旋转时，局部区域的梯度分布模式不变，矩阵 M 的特征值大小仅与梯度强度相关，与方向无关，因此 R 值不变，角点检测结果不受旋转影响。
- **尺度不变性（Scale Invariance）**：否。尺度变化会改变局部窗口内的梯度分布 —— 小尺度下的角点，在大尺度下可能表现为边缘；反之，大尺度下的角点，在小尺度下可能被噪声干扰。由于 Harris 检测器的窗口大小固定，无法适应不同尺度，因此不具备尺度不变性。

------

## 14.pdf 第 8 页（Feature Engineering I: SIFT & SURF - 特征工程 I：尺度不变特征变换与加速鲁棒特征）

### SIFT（尺度不变特征变换，Scale-Invariant Feature Transform）

#### 1. 核心特性（Core Properties）

- **不变性**：具备**旋转不变性（Rotation Invariance）**、**尺度不变性（Scale Invariance）**、**亮度不变性（Brightness Invariance）**，能在图像旋转、缩放、光照变化时稳定检测特征点。
- **功能定位**：图像局部特征描述子，不仅能检测特征点位置，还能生成具有区分性的特征描述符，用于跨图像特征匹配。

#### 2. SIFT 算法四步骤（Four Steps of SIFT Algorithm）

1. **多尺度极值检测（Multi-scale Extrema Detection）**：
   - 构建**高斯金字塔（Gaussian Pyramid）**：对图像反复进行高斯平滑（不同 σ 值）和下采样，得到不同尺度的图像层。
   - 构建**高斯差分金字塔（Difference of Gaussians, DoG）**：计算高斯金字塔中相邻尺度层的差值，得到 DoG 图像，其极值点（比周围 26 个邻居大或小）即为潜在特征点。
2. **特征点定位（Keypoint Localization）**：
   - 对 DoG 极值点进行**二阶泰勒级数展开**，实现亚像素级精确定位。
   - 去除**低对比度点**（展开后响应值小于阈值，如 0.03）和**边缘点**（黑塞矩阵特征值比值过大，如 10），保留稳定特征点。
3. **方向赋值（Orientation Assignment）**：
   - 以特征点为中心，取半径 3σ 的邻域，计算像素的梯度幅度和方向。
   - 构建**梯度方向直方图**（36 个 bin，每 10° 一个），取直方图峰值对应的方向作为特征点的**主方向**；若存在其他峰值（大于主峰值 80%），则分配多个方向，提高匹配鲁棒性。
4. **特征点描述符生成（Keypoint Descriptor）**：
   - 将特征点邻域旋转至主方向，划分为 4×4 的单元网格（16 个单元）。
   - 每个单元内计算 8 个方向的梯度直方图，拼接得到 16×8=128 维的 SIFT 描述符。
   - 对描述符进行**L2 归一化**，消除光照对比度变化的影响。

### SURF（加速鲁棒特征，Speeded-Up Robust Features）

#### 1. 核心定位（Core Positioning）

- **SIFT 的加速版本**：性能与 SIFT 相当，但运行速度比 SIFT 快 3 倍，适用于实时性要求较高的场景。
- **优势场景**：擅长处理模糊（Blurring）和旋转（Rotation）图像；**劣势场景**：不擅长处理视角变化（Viewpoint Change）和光照变化（Illumination Change）。

#### 2. 关键优化技术（Key Optimization Technologies）

- **盒式滤波器近似（Box Filter Approximation）**：用盒式滤波器替代 SIFT 中的高斯差分（DoG）。盒式滤波器窗口内所有像素权重相同，可通过**积分图像（Integral Image）** 快速计算卷积结果，无需逐像素卷积，大幅降低计算复杂度。
- **积分图像加速（Integral Image Acceleration）**：
  - 积分图像定义：\(A(x,y) = \sum_{x' \leq x, y' \leq y} I(x',y')\)，即 A (x,y) 是原始图像 I 中左上角到 (x,y) 的矩形区域像素和。
  - 任意矩形区域求和：通过积分图像，仅需 3 次加减运算即可得到任意矩形区域的像素和（\(A(x_2,y_2) - A(x_1,y_2) - A(x_2,y_1) + A(x_1,y_1)\)），支持多尺度并行计算。

### SIFT 与 SURF 对比（SIFT vs. SURF）

| 对比维度（Comparison Dimension）      | SIFT                       | SURF                                             |
| ------------------------------------- | -------------------------- | ------------------------------------------------ |
| 速度（Speed）                         | 较慢，128 维描述符计算复杂 | 较快，比 SIFT 快 3 倍，盒式滤波器 + 积分图像优化 |
| 尺度不变性（Scale Invariance）        | 强                         | 较强，略逊于 SIFT                                |
| 旋转不变性（Rotation Invariance）     | 强                         | 强                                               |
| 光照鲁棒性（Illumination Robustness） | 强                         | 较弱                                             |
| 视角鲁棒性（Viewpoint Robustness）    | 中等                       | 较弱                                             |
| 专利限制（Patent Restriction）        | 有，商业使用需授权         | 有，商业使用需授权                               |

------

## 14.pdf 第 9 页（Feature Engineering II: Linear Regression & GD - 特征工程 II：线性回归与梯度下降）

### 线性回归（Linear Regression）

#### 1. 核心目标（Core Goal）

线性回归是一种监督学习算法，用于建立输入特征 x 与连续输出 y 之间的线性关系，核心是**找到最优参数 θ**，使预测值\(h_θ(x)\)与真实值 y 的差异最小。

#### 2. 模型公式（Model Formula）

- **假设函数（Hypothesis Function）**：\(h_θ(x) = θ_0 + θ_1 x_1 + θ_2 x_2 + ... + θ_d x_d = θ^T x\)，其中 θ 是参数向量（θ₀为偏置项，θ₁~θ_d 为特征权重），x 是输入特征向量（x₀=1，x₁~x_d 为输入特征）。

- **损失函数（Cost Function）**：采用**均方误差（Mean Squared Error, MSE）**，衡量预测值与真实值的平均平方差，优化目标是最小化损失函数：

  

  \(\min _{θ} L(θ) = \frac{1}{2} \sum_{i=1}^{n} \left[ h_θ(x^{(i)}) - y^{(i)} \right]^2\)

  

  其中 n 是样本数量，

  \(x^{(i)}\)

  、

  \(y^{(i)}\)

  分别是第 i 个样本的输入和真实输出，系数 1/2 是为了简化后续求导计算。

#### 3. 损失函数的几何意义（Geometric Meaning of Cost Function）

- 线性回归的本质是**最小化预测超平面与真实数据点之间的距离**，属于**最小二乘估计（Least Squares Estimation, LSE）** 问题。
- 例如，单特征线性回归（y=θ₀+θ₁x）中，损失函数对应预测直线与所有真实数据点的纵向距离平方和，最优参数 θ 使该平方和最小。

### 梯度下降（Gradient Descent, GD）

#### 1. 核心思想（Core Idea）

梯度下降是一种迭代优化算法，用于求解损失函数的最小值。其核心是**沿损失函数梯度的负方向（最陡下降方向）逐步更新参数**，直至损失函数收敛到最小值（或局部最小值）。

#### 2. 参数更新公式（Parameter Update Formula）

- 初始化参数 θ（如随机初始化或全零初始化），然后反复执行以下更新：

  

  \(θ^{t+1} = θ^t - α \cdot \nabla_θ L(θ^t)\)

  

  其中：

  

  - \(θ^t\)：第 t 次迭代后的参数值。
  - \(θ^{t+1}\)：第 t+1 次迭代后的参数值。
  - α：**学习率（Learning Rate）**，控制每次参数更新的步长，α 过大会导致震荡不收敛，α 过小会导致收敛过慢。
  - \(\nabla_θ L(θ^t)\)：损失函数在\(θ^t\)处的梯度，即损失函数对每个参数 θ_j 的偏导数（\(\frac{\partial L(θ)}{\partial θ_j}\)）。

#### 3. 梯度下降的几何意义（Geometric Meaning of GD）

- 损失函数可视为一个 “山谷”，梯度方向是 “上坡” 方向，负梯度方向是 “下坡” 方向。每次参数更新相当于沿 “下坡” 走一步，逐步靠近山谷底部（损失最小值）。
- （图中为损失函数随迭代次数变化的折线图，纵轴为损失值，范围 0~20，横轴为迭代次数，损失值随迭代次数增加逐渐下降并收敛）

#### 4. 线性回归的梯度下降实现（GD Implementation for Linear Regression）

- 损失函数对 θ_j 的偏导数：\(\frac{\partial L(θ)}{\partial θ_j} = \sum_{i=1}^n \left[ h_θ(x^{(i)}) - y^{(i)} \right] x_j^{(i)}\)。
- 参数更新规则：\(θ_j^{t+1} = θ_j^t - α \cdot \sum_{i=1}^n \left[ h_θ(x^{(i)}) - y^{(i)} \right] x_j^{(i)}\)（批量梯度下降，使用所有样本计算梯度）。

### 线性回归的两种优化方法（Two Optimization Methods for Linear Regression）

| 方法（Method）        | 核心原理（Core Principle）                                   | 优点（Advantages）                                           | 缺点（Disadvantages）                                        | 适用场景（Applicable Scenarios）                |
| --------------------- | ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ | ----------------------------------------------- |
| 闭式解（Closed Form） | 直接通过矩阵运算求解参数 θ：\(θ = (X^T X)^{-1} X^T y\)（X 为特征矩阵，y 为真实输出向量） | 无需迭代，一步得到最优解；无学习率选择问题                   | 需计算矩阵逆，时间复杂度 O (d³)（d 为特征维度）；当 X^T X 不可逆时无法使用 | 特征维度 d 较小（如 d<1000）的场景              |
| 梯度下降（GD）        | 迭代沿负梯度方向更新参数                                     | 时间复杂度低（每次迭代 O (n*d)）；适用于高维数据和大规模样本 | 需迭代多次收敛；需选择合适的学习率                           | 特征维度 d 大（如 d>1000）、样本数量 n 多的场景 |

------

## 14.pdf 第 10 页（Feature Engineering II: Binary Classification & SVM - 特征工程 II：二分类与支持向量机）

### 二分类问题（Binary Classification）

#### 1. 问题定义（Problem Definition）

二分类是将输入样本分为两个互斥类别的监督学习任务，例如判断邮件是否为垃圾邮件（“垃圾邮件” vs “正常邮件”）、判断肿瘤是否为恶性（“恶性” vs “良性”）。

- **标签定义**：通常将两个类别标记为 y=0 和 y=1（或 y=-1 和 y=1），其中 y=1 表示 “正类”（如垃圾邮件），y=0 表示 “负类”（如正常邮件）。
- **核心挑战**：当数据在原始特征空间中**线性不可分时**（即无法用一条直线 / 平面分开两类样本），传统线性分类器（如逻辑回归）性能受限，需引入非线性处理方法。

### 支持向量机（Support Vector Machine, SVM）

#### 1. 核心思想（Core Idea）

SVM 是一种强大的线性分类器，其核心是**找到最优分类超平面**—— 该超平面不仅能正确分开两类样本（尽可能），还能使超平面到两类样本的**最小距离（Margin）最大化**。这种 “最大间隔” 特性使 SVM 具有良好的泛化能力，能有效应对过拟合。

#### 2. 分类超平面与间隔（Classification Hyperplane & Margin）

- **分类超平面公式**：对于 d 维特征空间，分类超平面的方程为\(w^T x + b = 0\)，其中：
  - w：超平面的法向量（与超平面垂直），决定超平面的方向。
  - b：偏置项（Offset Term），决定超平面的位置。
- **样本分类规则**：
  - 若\(w^T x + b \geq 1\)，则预测为正类（y=1）。
  - 若\(w^T x + b \leq -1\)，则预测为负类（y=0 或 y=-1）。
- **间隔（Margin）**：超平面到最近样本的距离，计算公式为\(\frac{2}{\|w\|}\)（|w | 是 w 的 L2 范数）。SVM 的优化目标是最大化该间隔，即最小化 | w|（等价于最小化\(\frac{1}{2}\|w\|^2\)），同时满足分类约束（所有样本正确分类）。

#### 3. 支持向量（Support Vectors）

- **定义**：距离分类超平面最近的样本点，即满足\(w^T x^{(i)} + b = 1\)（正类）或\(w^T x^{(i)} + b = -1\)（负类）的样本点。
- **特性**：
  - 支持向量决定了最优分类超平面的位置和间隔大小，非支持向量的移动（只要不跨越超平面）不会影响超平面。
  - 在 SVM 的对偶问题求解中，仅支持向量对应的拉格朗日乘子\(α_i^* \neq 0\)，非支持向量的\(α_i^* = 0\)（即非支持向量对参数优化无贡献）。

#### 4. 核技巧（Kernel Trick）—— 处理线性不可分问题

- **核心原理**：当数据在原始特征空间线性不可分时，通过**核函数（Kernel Function）** 将原始特征 x 映射到高维特征空间\(φ(x)\)，使数据在高维空间中线性可分，再使用 SVM 进行分类。
- **常用核函数**：
  - 线性核（Linear Kernel）：\(K(x_1,x_2) = x_1^T x_2\)（适用于线性可分数据）。
  - 多项式核（Polynomial Kernel）：\(K(x_1,x_2) = (x_1^T x_2 + c)^d\)（c 为常数，d 为多项式次数，适用于低维非线性数据）。
  - 高斯核（RBF Kernel）：\(K(x_1,x_2) = e^{-\gamma \|x_1 - x_2\|^2}\)（γ 为带宽参数，适用于高维非线性数据，应用最广泛）。
- **示例**：（图中为二维非线性数据，原始空间中无法用直线分开，通过核函数映射到三维空间后，可用平面分开）

#### 5. SVM 二分类示例（SVM Binary Classification Example）

（图中展示二维样本数据，正类样本为 (3,0)、(2,1)，负类样本为 (1,2)、(0,3)，分类超平面为 x+y=3，支持向量为 (3,0)、(2,1)、(1,2)、(0,3)）

- **样本特征计算**：

  

  | 样本（Sample） | x+y | xy | x² |

  

  | ---- | ---- | ---- | ---- |

  

  | (0,3) | 3 | 0 | 0 |

  

  | (1,2) | 3 | 2 | 1 |

  

  | (2,1) | 3 | 2 | 4 |

  

  | (3,0) | 3 | 0 | 9 |

- **核映射效果**：原始空间中 x+y=3 的直线无法区分样本，但通过核函数（如 x²）映射到高维空间后，可找到线性分类超平面。

------

## 14.pdf 第 11 页（Feature Engineering II: Multi-class Classification & Clustering - 特征工程 II：多分类与聚类）

### 多分类问题（Multi-class Classification）

#### 1. 问题定义（Problem Definition）

多分类是将输入样本分为 K 个互斥类别的监督学习任务（K≥3），例如手写数字识别（10 个类别：0~9）、图像分类（如 ImageNet 的 1000 个类别）。

- **标签定义**：样本标签\(y^{(i)} \in \{1,2,...,K\}\)，K 为类别总数。
- **与二分类的区别**：二分类仅需区分 “是” 或 “否”，多分类需在多个类别中选择唯一正确类别，无法直接通过 “一对一” 或 “一对多” 的二分类简单扩展（需特殊处理类别间的竞争关系）。

#### 2. 多分类模型：Softmax 回归（Softmax Regression）

- **核心思想**：将线性回归的输出转换为类别概率分布，通过 Softmax 函数使每个类别的预测概率在 [0,1] 之间，且所有类别概率之和为 1，选择概率最大的类别作为预测结果。

- **模型公式**：

  1. **线性输出**：对每个样本 x，计算 K 个线性输出\(z_j = θ_j^T x\)（j=1~K，θ_j 是第 j 类的参数向量）。

  2. **Softmax 函数**：将线性输出 z 转换为类别概率\(\hat{y}_j\)（预测样本属于第 j 类的概率）：

     

     \(\sigma(z)_j = \hat{y}_j = \frac{e^{z_j}}{\sum_{k=1}^K e^{z_k}} \quad (j=1,...,K)\)

  3. **预测规则**：选择概率最大的类别，即\(y_{pred} = \arg\max_j \hat{y}_j\)。

- **损失函数**：采用**交叉熵损失（Cross-Entropy Loss）**，衡量预测概率分布与真实标签分布的差异：

  \(L(θ) = -\frac{1}{n} \sum_{i=1}^n \sum_{j=1}^K y_j^{(i)} \log \hat{y}_j^{(i)}\)

  其中\(y_j^{(i)}\)是真实标签的独热编码（One-Hot Encoding）—— 若第 i 个样本属于第 j 类，则\(y_j^{(i)}=1\)，否则\(y_j^{(i)}=0\)。

#### 3. 多分类与二分类的对比（Multi-class vs. Binary Classification）

| 对比维度（Comparison Dimension） | 二分类（Binary Classification）                  | 多分类（Multi-class Classification）    |
| -------------------------------- | ------------------------------------------------ | --------------------------------------- |
| 类别数量（Number of Classes）    | 2（y∈{0,1}）                                     | K≥3（y∈{1,2,...,K}）                    |
| 输出形式（Output Form）          | 单个概率（属于正类的概率）                       | K 个概率（属于每个类别的概率，和为 1）  |
| 核心函数（Core Function）        | Sigmoid 函数（\(\sigma(x)=\frac{1}{1+e^{-x}}\)） | Softmax 函数                            |
| 损失函数（Loss Function）        | 二元交叉熵（Binary Cross-Entropy）               | 多类交叉熵（Categorical Cross-Entropy） |
| 典型模型（Typical Models）       | 逻辑回归（Logistic Regression）、二分类 SVM      | Softmax 回归、多分类 SVM、CNN           |

### 聚类（Clustering）—— 无监督学习

#### 1. 问题定义（Problem Definition）

聚类是一种无监督学习任务，当**没有真实标签（Groundtruth Labels）** 时，通过分析样本的内在特征相似性，将样本自动划分为多个簇（Clusters），使同一簇内的样本相似度高，不同簇间的样本相似度低。

- **核心目标**：发现数据的自然分组结构，例如用户行为聚类（将相似购物习惯的用户分为一组）、图像内容聚类（将相似场景的图像分为一组）。

#### 2. 典型聚类算法：K-means

- **核心思想**：预先指定簇的数量 K，通过迭代优化，将样本分配到最近的簇中心，同时更新簇中心为该簇所有样本的均值，直至簇中心不再变化（或变化小于阈值）。
- **K-means 算法步骤**：
  1. **初始化**：随机选择 K 个样本作为初始簇中心（Centroids）。
  2. **分配样本**：对每个样本，计算其与所有簇中心的距离（如欧氏距离），将样本分配到距离最近的簇。
  3. **更新簇中心**：对每个簇，计算该簇内所有样本的均值，作为新的簇中心。
  4. **迭代收敛**：重复步骤 2 和 3，直至簇中心的变化量小于预设阈值，或迭代次数达到上限。
- **关键参数**：簇数量 K 的选择需结合业务场景（如已知用户分为 3 类），或通过肘部法则（Elbow Method）—— 绘制簇内平方和（WCSS）随 K 变化的曲线，选择曲线 “肘部” 对应的 K（WCSS 下降速率骤减的点）。

#### 3. 聚类与分类的对比（Clustering vs. Classification）

| 对比维度（Comparison Dimension） | 分类（Classification）                     | 聚类（Clustering）                                |
| -------------------------------- | ------------------------------------------ | ------------------------------------------------- |
| 监督类型（Supervision Type）     | 监督学习（有真实标签）                     | 无监督学习（无真实标签）                          |
| 核心目标（Core Goal）            | 学习从特征到标签的映射，用于预测新样本标签 | 发现数据的自然簇结构，无需预测                    |
| 输入数据（Input Data）           | 带标签的训练样本（x, y）                   | 无标签的样本（x）                                 |
| 典型算法（Typical Algorithms）   | 逻辑回归、SVM、CNN                         | K-means、高斯混合模型（GMM）、层次聚类            |
| 结果评估（Result Evaluation）    | 准确率（Accuracy）、F1 分数、混淆矩阵      | 轮廓系数（Silhouette Score）、Davies-Bouldin 指数 |

#### 4. 高斯混合模型（Gaussian Mixture Model, GMM）

- **核心思想**：假设数据由多个高斯分布（正态分布）混合生成，每个高斯分布对应一个簇，通过估计每个高斯分布的参数（均值、协方差、权重），实现软聚类（每个样本属于每个簇的概率）。
- **与 K-means 的区别**：K-means 是硬聚类（每个样本仅属于一个簇），GMM 是软聚类（每个样本有属于不同簇的概率）；GMM 能处理非球形簇（通过协方差矩阵控制簇形状），K-means 仅适用于球形簇。
- （图中展示数据分布：左图为单高斯分布（Single Gaussian），数据集中在一个区域；右图为两个高斯混合分布（Mixture of two Gaussians），数据分为两个明显的簇）

------

## 14.pdf 第 12 页（Deep Fully-connected Neural Networks - 深度全连接神经网络）

### 网络结构（Network Structure）

深度全连接神经网络（Deep Fully-connected Neural Networks，简称 DNN）由输入层（Input Layer）、多个隐藏层（Hidden Layers）和输出层（Output Layer）组成，层与层之间的神经元完全连接（每个神经元与下一层所有神经元连接）。

- **输入层（Inputs）**：接收原始特征数据，神经元数量等于输入特征维度（如输入为 28×28 的图像，展开后输入层神经元数量为 784）。
- **隐藏层（Hidden States）**：位于输入层和输出层之间，层数（深度）和每层神经元数量是超参数，用于提取数据的复杂非线性特征。深层网络（如 10 层以上）能捕捉更抽象的语义特征。
- **输出层（Outputs）**：输出模型预测结果，神经元数量根据任务确定 —— 二分类任务输出层 1 个神经元（Sigmoid 激活），多分类任务输出层 K 个神经元（Softmax 激活），回归任务输出层 1 个神经元（无激活）。

### 神经元计算过程（Neuron Calculation Process）

#### 1. 线性变换（Linear Transformation）

对于第 k 层的第 i 个神经元，其输入是第 k-1 层所有神经元的输出经过线性加权求和，并加上偏置项：

\(z_i^{(k)} = b_i^{(k)} + \sum_{j=1}^{d_{k-1}} w_{i,j}^{(k)} \cdot a_j^{(k-1)}\)

其中：

- \(z_i^{(k)}\)：第 k 层第 i 个神经元的线性输出（未激活）。
- \(b_i^{(k)}\)：第 k 层第 i 个神经元的偏置项（Bias）。
- \(w_{i,j}^{(k)}\)：第 k 层第 i 个神经元与第 k-1 层第 j 个神经元之间的权重（Weight）。
- \(a_j^{(k-1)}\)：第 k-1 层第 j 个神经元的激活输出（经过激活函数处理后的输出）。
- \(d_{k-1}\)：第 k-1 层的神经元数量。

#### 2. 激活函数（Activation Function）

激活函数为神经网络引入非线性，使网络能拟合复杂的非线性数据关系（若仅用线性变换，深层网络与单层线性模型等价）。常用激活函数如下：

| 激活函数（Activation Function） | 公式（Formula）                                              | 特性（Properties）                                           | 适用场景（Applicable Scenarios）             |
| ------------------------------- | ------------------------------------------------------------ | ------------------------------------------------------------ | -------------------------------------------- |
| Sigmoid                         | \(\sigma(x) = \frac{1}{1 + e^{-x}}\)                         | 输出在 (0,1) 之间，可表示概率；存在梯度消失问题（x 过大 / 过小时导数接近 0） | 二分类任务输出层；早期网络隐藏层（现已少用） |
| Tanh                            | \(\tanh(x) = \frac{e^x - e^{-x}}{e^x + e^{-x}}\)             | 输出在 (-1,1) 之间，均值为 0；仍存在梯度消失问题             | 隐藏层（比 Sigmoid 更常用，避免均值偏移）    |
| ReLU（Rectified Linear Unit）   | \(ReLU(x) = \max(0, x)\)                                     | 计算简单，缓解梯度消失（x>0 时导数为 1）；存在 “死亡 ReLU” 问题（x≤0 时导数为 0，神经元永久失活） | 现代 CNN、DNN 的隐藏层（最常用）             |
| Leaky ReLU                      | \(Leaky ReLU(x) = \max(αx, x)\)（α 通常为 0.01）             | 解决死亡 ReLU 问题（x≤0 时导数为 α，非零）；计算略复杂       | 隐藏层（当 ReLU 效果不佳时使用）             |
| ELU（Exponential Linear Unit）  | \(\begin{cases} x & x \geq 0 \\ α(e^x - 1) & x < 0 \end{cases}\) | 均值接近 0，抗噪声能力强；计算复杂度较高                     | 对噪声敏感的任务（如图像去噪）               |

#### 3. 激活输出（Activation Output）

第 k 层第 i 个神经元的最终输出为线性输出经过激活函数处理的结果：

\(a_i^{(k)} = g(z_i^{(k)})\)

其中 g (・) 为激活函数（如 ReLU、Sigmoid）。

### 反向传播（Backward Propagation）

反向传播是训练深度神经网络的核心算法，用于计算损失函数对每个参数（权重 w 和偏置 b）的梯度，为梯度下降优化提供依据。其核心是**链式法则（Chain Rule）**—— 从输出层到输入层，逐层计算梯度。

#### 1. 反向传播步骤（Backward Propagation Steps）

1. **前向传播（Forward Pass）**：计算各层的线性输出 z 和激活输出 a，直至得到输出层预测值\(\hat{y}\)，并计算损失函数 L（如交叉熵损失、均方误差）。

2. **初始化梯度（Initialize Gradient）**：计算输出层的误差项 δ（损失函数对输出层线性输出 z^(n) 的梯度）：

   - 若为回归任务（MSE 损失）：\(\delta^{(n)} = \frac{\partial L}{\partial z^{(n)}} = \hat{y} - y\)。
   - 若为多分类任务（交叉熵损失 + Softmax）：\(\delta^{(n)} = \frac{\partial L}{\partial z^{(n)}} = \hat{y} - y\)（独热编码 y）。

3. **逐层反向计算误差项**：从输出层（第 n 层）向输入层（第 1 层）迭代，计算每一层的误差项 δ^(k)：

   

   \(\delta^{(k)} = \left( (w^{(k+1)})^T \cdot \delta^{(k+1)} \right) \odot g'(z^{(k)})\)

   

   其中：

   

   - \(w^{(k+1)}\)：第 k+1 层的权重矩阵。
   - \(g'(z^{(k)})\)：激活函数 g 在 z^(k) 处的导数（如 ReLU 的导数为 1（x>0）或 0（x≤0））。
   - ⊙：逐元素乘法（Hadamard Product）。

4. **计算参数梯度**：根据误差项 δ^(k)，计算损失函数对第 k 层权重 w^(k) 和偏置 b^(k) 的梯度：

   

   \(\frac{\partial L}{\partial w^{(k)}} = \delta^{(k)} \cdot (a^{(k-1)})^T\)

   

   \(\frac{\partial L}{\partial b^{(k)}} = \text{sum}(\delta^{(k)}) \quad (\text{对样本维度求和})\)

5. **参数更新**：使用梯度下降（或其变种，如 Adam）更新权重和偏置：

   

   \(w^{(k)} = w^{(k)} - α \cdot \frac{\partial L}{\partial w^{(k)}}\)

   

   \(b^{(k)} = b^{(k)} - α \cdot \frac{\partial L}{\partial b^{(k)}}\)

#### 2. 反向传播示例（Backward Propagation Example）

（图中展示两层神经网络的反向传播过程：输入层 x→隐藏层 z^(1)→激活 a^(1)→输出层 z^(2)→激活 a^(2)→损失 L。反向传播时，从 L 出发，计算\(\frac{\partial L}{\partial a^{(2)}}\)→\(\frac{\partial L}{\partial z^{(2)}}\)（δ^(2)）→\(\frac{\partial L}{\partial w^{(2)}}\)→\(\frac{\partial L}{\partial a^{(1)}}\)→\(\frac{\partial L}{\partial z^{(1)}}\)（δ^(1)）→\(\frac{\partial L}{\partial w^{(1)}}\)）

- 核心公式示例（两层网络）：

  

  \(\frac{\partial L}{\partial w^{(1)}} = \frac{\partial L}{\partial z^{(2)}} \cdot \frac{\partial z^{(2)}}{\partial a^{(1)}} \cdot \frac{\partial a^{(1)}}{\partial z^{(1)}} \cdot \frac{\partial z^{(1)}}{\partial w^{(1)}}\)

------

## 14.pdf 第 13 页（Other Layers: CNNs - 其他层：卷积神经网络）

### 全连接层的局限性（Limitations of Fully-connected Layers）

在图像处理任务中，传统全连接层存在明显缺陷：

- **丢失空间信息（Losing Spatial Information）**：全连接层需将图像（如 32×32×3 的 RGB 图像）拉伸为一维向量（3072×1），破坏图像的空间结构（如像素的邻域关系、纹理分布），而空间信息对图像识别至关重要（如判断 “猫” 需要知道眼睛、耳朵的相对位置）。
- **参数数量庞大（Huge Number of Parameters）**：若输入向量为 3072 维，输出为 10 维（如 10 分类任务），全连接层的权重参数数量为 10×3072=30720，深层网络中参数数量会急剧增加，导致过拟合和计算成本过高。

### 卷积层（Convolutional Layer）—— CNN 的核心

卷积层是卷积神经网络（Convolutional Neural Network, CNN）的核心组件，通过**卷积运算（Convolution）** 提取图像的空间特征（如边缘、纹理、形状），保留空间信息且参数共享。

#### 1. 卷积运算原理（Convolution Operation Principle）

- **二维卷积公式**：对于输入特征图 f (x,y) 和卷积核 h (x,y)，卷积结果 g (x,y) 为：

  

  \(g(x,y) = f(x,y) * h(x,y) = \iint f(u,v) \cdot h(u-x, v-y) \, du dv\)

  

  在离散图像中，积分替换为求和：

  

  \(g(x,y) = \sum_{u} \sum_{v} f(u,v) \cdot h(u-x, v-y)\)

  

  其中：

  

  

  - f (x,y)：输入特征图（如原始图像、前一层卷积输出）。
  - h (x,y)：卷积核（Filter），是一个小型可学习的权重矩阵（如 3×3、5×5），每个卷积核对应一种特征（如水平边缘、垂直边缘）。
  - g (x,y)：卷积输出特征图（Feature Map），每个像素是输入特征图与卷积核的局部加权和。

#### 2. 卷积层的关键参数（Key Parameters of Convolutional Layer）

| 参数（Parameter）                      | 定义（Definition）                        | 作用（Function）                                             |
| -------------------------------------- | ----------------------------------------- | ------------------------------------------------------------ |
| 卷积核数量（Number of Filters, C_out） | 卷积层使用的卷积核总数                    | 决定输出特征图的通道数（C_out），每个卷积核提取一种特征      |
| 卷积核大小（Filter Size, K×K）         | 卷积核的高度和宽度（如 3×3、5×5）         | 控制局部感受野大小（K×K），小核（3×3）提取细节特征，大核（7×7）提取全局特征 |
| 步长（Stride, S）                      | 卷积核在输入特征图上滑动的步长（如 1、2） | 控制输出特征图的尺寸：输出高度 H' = (H - K + 2P)/S + 1，宽度 W' = (W - K + 2P)/S + 1（H、W 为输入高度、宽度；P 为填充） |
| 填充（Padding, P）                     | 在输入特征图边缘填充的像素数（如 0、1）   | 避免边缘特征丢失，控制输出特征图尺寸（如 “Same Padding” 使 H'=H、W'=W；“Valid Padding” 使 P=0） |

#### 3. 卷积层的输入与输出形状（Input & Output Shape of Convolutional Layer）

- **输入形状**：N×C_in×H×W，其中 N 为批量大小（Batch Size），C_in 为输入特征图通道数（如 RGB 图像 C_in=3），H 为输入高度，W 为输入宽度。
- **输出形状**：N×C_out×H'×W，其中 C_out 为卷积核数量，H'、W' 为输出高度和宽度（由步长和填充决定）。
- **偏置项（Bias）**：每个卷积核对应一个偏置项，共 C_out 个偏置（如 64 个卷积核对应 64 维偏置向量）。

### 池化层（Pooling Layer）

池化层用于**下采样（Downsampling）**，减少特征图尺寸和参数数量，降低计算成本，同时增强模型对微小位移和变形的鲁棒性（实现局部不变性）。

#### 1. 常用池化方法（Common Pooling Methods）

| 池化方法（Pooling Method）  | 计算方式（Calculation Method）                     | 特性（Properties）                             | 适用场景（Applicable Scenarios）     |
| --------------------------- | -------------------------------------------------- | ---------------------------------------------- | ------------------------------------ |
| 最大池化（Max Pooling）     | 取池化窗口内的最大值作为输出                       | 保留局部区域的显著特征（如边缘强度），鲁棒性强 | 大部分 CNN 隐藏层（如 AlexNet、VGG） |
| 平均池化（Average Pooling） | 取池化窗口内的平均值作为输出                       | 保留局部区域的整体信息，平滑性好               | 网络最后几层（如分类任务的输出层前） |
| 全局池化（Global Pooling）  | 对整个特征图取最大 / 平均值，输出 1×1×C_out 的特征 | 替代全连接层，减少参数数量，避免过拟合         | 轻量级网络（如 MobileNet）的输出层前 |

#### 2. 池化层示例（Pooling Layer Example）

（图中展示 2×2 最大池化：输入特征图为 4×4，池化窗口 2×2，步长 2。输入区域 [[1,2],[3,4]] 输出 4，[[5,6],[7,8]] 输出 8，[[3,2],[1,0]] 输出 3，[[1,2],[3,4]] 输出 4，最终输出 2×2 的特征图）

- **效果**：输入尺寸从 4×4 降至 2×2（下采样 2 倍），参数数量减少，同时保留了每个局部区域的最大特征值。

### CNN 的核心优势（Core Advantages of CNN）

1. **参数共享（Parameter Sharing）**：一个卷积核在整个输入特征图上共享，无需为每个像素单独学习权重，大幅减少参数数量（如 32×32×3 图像用 3×3×3 卷积核，参数数量仅 27，远少于全连接层的 3072×K）。
2. **局部感受野（Local Receptive Field）**：卷积核仅关注输入的局部区域，模拟人类视觉的局部感知特性（如先识别边缘，再组合成形状），符合图像的空间结构特性。
3. **层次化特征提取（Hierarchical Feature Extraction）**：浅层卷积层提取低级特征（如边缘、纹理），深层卷积层提取高级特征（如物体部件、整体形状），逐步构建复杂的语义表示，对图像识别任务至关重要。

------

## 14.pdf 第 14 页（GANs, RNNs - 生成对抗网络与循环神经网络）

### 生成对抗网络（Generative Adversarial Networks, GANs）

#### 1. 核心思想（Core Idea）

GANs 由生成器（Generator）和判别器（Discriminator）两个网络组成，通过**对抗训练（Adversarial Training）** 实现生成逼真数据的目标：

- **生成器 G（Generator）**：输入随机噪声 z，生成与真实数据分布相似的伪造数据 G (z)（如伪造图像、伪造文本），目标是让伪造数据尽可能接近真实数据，欺骗判别器。
- **判别器 D（Discriminator）**：输入真实数据 x 或伪造数据 G (z)，输出数据为真实数据的概率 D (x)（或 D (G (z))），目标是准确区分真实数据和伪造数据，不被生成器欺骗。
- **对抗过程**：生成器和判别器不断博弈 —— 生成器优化参数使 D (G (z)) 尽可能大（接近 1，让判别器认为伪造数据是真实的），判别器优化参数使 D (x) 尽可能大（接近 1）且 D (G (z)) 尽可能小（接近 0），最终达到纳什均衡（生成器生成的伪造数据与真实数据难以区分，判别器准确率接近 50%）。

#### 2. GANs 的网络结构与训练目标（Network Structure & Training Objective）

- **生成器 G**：通常为反卷积网络（Deconvolutional Network）或转置卷积网络（Transposed Convolutional Network），将低维噪声 z 映射到高维数据空间（如 256×256×3 的图像）。
- **判别器 D**：通常为卷积网络（Convolutional Network），将高维数据（如图像）映射到单个概率值（0~1），判断输入数据的真实性。
- **损失函数**：
  1. **判别器损失（Discriminator Loss）**：
     - 对真实数据 x，希望 D (x) 接近 1，损失项为\(-\mathbb{E}_{x \sim p_{data}} [\log D(x)]\)。
     - 对伪造数据 G (z)，希望 D (G (z)) 接近 0，损失项为\(-\mathbb{E}_{z \sim p_z} [\log (1 - D(G(z)))]\)。
     - 总判别器损失：\(L_D = -\mathbb{E}_{x \sim p_{data}} [\log D(x)] - \mathbb{E}_{z \sim p_z} [\log (1 - D(G(z)))]\)。
  2. **生成器损失（Generator Loss）**：
     - 希望 D (G (z)) 接近 1，损失项为\(-\mathbb{E}_{z \sim p_z} [\log D(G(z))]\)（或等价的\(\mathbb{E}_{z \sim p_z} [\log (1 - D(G(z)))]\)）。
     - 总生成器损失：\(L_G = -\mathbb{E}_{z \sim p_z} [\log D(G(z))]\)。

#### 3. GANs 的应用场景（Application Scenarios）

- **图像生成**：生成逼真的人脸图像（如 StyleGAN）、风景图像、艺术作品。
- **图像编辑**：图像修复（填补缺失区域）、图像风格迁移（如将照片转换为油画）。
- **数据增强**：为小样本任务生成额外的训练数据（如医学影像数据增强）。
- **文本生成**：生成逼真的文本（如 GAN 结合 RNN/Transformer 生成文章、诗歌）。

### 循环神经网络（Recurrent Neural Networks, RNNs）

#### 1. 核心思想（Core Idea）

RNNs 是一种处理序列数据（如文本、语音、视频帧）的神经网络，其核心是**通过隐藏状态（Hidden State）传递序列的上下文信息**—— 当前时刻的输出不仅依赖当前时刻的输入，还依赖前一时刻的隐藏状态，模拟人类处理序列数据的时序特性（如阅读文本时，需结合前文理解当前句子）。

#### 2. RNNs 的基本结构（Basic Structure of RNNs）

- **输入（Input）**：序列数据\(x^{(1)}, x^{(2)}, ..., x^{(T)}\)，其中 T 为序列长度，\(x^{(t)}\)为第 t 时刻的输入向量。

- **隐藏状态（Hidden State）**：\(h^{(1)}, h^{(2)}, ..., h^{(T)}\)，第 t 时刻的隐藏状态\(h^{(t)}\)由当前输入\(x^{(t)}\)和前一时刻隐藏状态\(h^{(t-1)}\)共同决定：

  

  \(h^{(t)} = g(W_h h^{(t-1)} + W_x x^{(t)} + b_h)\)

  

  其中：

  

  - \(W_h\)：隐藏状态到隐藏状态的权重矩阵。
  - \(W_x\)：输入到隐藏状态的权重矩阵。
  - \(b_h\)：隐藏状态的偏置项。
  - g (・)：激活函数（如 tanh、ReLU）。

- **输出（Output）**：\(y^{(1)}, y^{(2)}, ..., y^{(T)}\)，第 t 时刻的输出\(y^{(t)}\)由当前隐藏状态\(h^{(t)}\)决定：

  

  \(y^{(t)} = g'(W_y h^{(t)} + b_y)\)

  

  其中

  \(W_y\)

  为隐藏状态到输出的权重矩阵，

  \(b_y\)

  为输出的偏置项，g'(・) 为输出层激活函数（如 Softmax 用于分类）。

#### 3. 长短期记忆网络（LSTM，一种改进的 RNN）

传统 RNN 存在**梯度消失 / 梯度爆炸问题**—— 当序列长度 T 较长时，反向传播过程中梯度会随时间步衰减（或激增），导致无法学习长期依赖关系（如理解长文本的上下文）。LSTM（Long Short-Term Memory）通过引入**门控机制（Gating Mechanism）** 解决该问题。

- **LSTM 的核心组件**：

  1. **遗忘门（Forget Gate）**：控制前一时刻隐藏状态\(h^{(t-1)}\)和细胞状态\(c^{(t-1)}\)中哪些信息需要被遗忘，输出门控值\(f^{(t)} \in [0,1]\)（1 表示完全保留，0 表示完全遗忘）：

     

     \(f^{(t)} = \sigma(W_f [h^{(t-1)}, x^{(t)}] + b_f)\)

  2. **输入门（Input Gate）**：控制当前输入\(x^{(t)}\)和前一时刻隐藏状态\(h^{(t-1)}\)中哪些信息需要被存入新的细胞状态\(\tilde{c}^{(t)}\)，输出门控值\(i^{(t)} \in [0,1]\)：

     

     \(i^{(t)} = \sigma(W_i [h^{(t-1)}, x^{(t)}] + b_i)\)

     

     \(\tilde{c}^{(t)} = \tanh(W_c [h^{(t-1)}, x^{(t)}] + b_c)\)

  3. **细胞状态（Cell State）**：LSTM 的 “记忆单元”，通过遗忘门和输入门更新，传递长期信息：

     

     \(c^{(t)} = f^{(t)} \odot c^{(t-1)} + i^{(t)} \odot \tilde{c}^{(t)}\)

  4. **输出门（Output Gate）**：控制细胞状态\(c^{(t)}\)中哪些信息需要被输出到当前隐藏状态\(h^{(t)}\)，输出门控值\(o^{(t)} \in [0,1]\)：

     

     \(o^{(t)} = \sigma(W_o [h^{(t-1)}, x^{(t)}] + b_o)\)

     

     \(h^{(t)} = o^{(t)} \odot \tanh(c^{(t)})\)

     

     其中

     \(\sigma\)

     为 Sigmoid 激活函数，

     \([h^{(t-1)}, x^{(t)}]\)

     表示向量拼接，⊙为逐元素乘法。

- **LSTM 的优势**：细胞状态可长期保存序列信息，门控机制灵活控制信息的遗忘、输入和输出，有效解决传统 RNN 的长期依赖问题，广泛应用于机器翻译、文本生成、语音识别等任务。

#### 4. RNNs 的应用场景（Application Scenarios）

- **自然语言处理（NLP）**：机器翻译（如 Encoder-Decoder 架构）、文本分类、情感分析、文本生成（如写诗、写故事）。
- **语音处理（Speech Processing）**：语音识别（将语音转换为文本）、语音合成（将文本转换为语音）、语音情感分析。
- **时间序列预测（Time Series Prediction）**：股票价格预测、气象预测、设备故障预测。
- **视频分析（Video Analysis）**：视频帧标注、动作识别（结合 CNN 提取图像特征，RNN 处理时序关系）。

------

## 14.pdf 第 15 页（Basic Concept of Graph and GNN - 图与图神经网络基础）

### 图的基本概念（Basic Concepts of Graph）

图（Graph）是一种用于表示实体间关系的数据结构，由节点（Vertices/Nodes）和边（Edges）组成，可描述复杂的非欧几里得数据（如社交网络、知识图谱、分子结构）。

#### 1. 图的组成要素（Components of Graph）

| 要素（Component）                         | 定义（Definition）                                 | 示例（Examples）                                             |
| ----------------------------------------- | -------------------------------------------------- | ------------------------------------------------------------ |
| 节点（Node/Vertex, V）                    | 图中的实体，每个节点可携带属性信息                 | 社交网络中的用户、知识图谱中的概念、分子结构中的原子         |
| 边（Edge, E）                             | 连接两个节点的关系，可携带属性信息（如权重、方向） | 社交网络中的 “好友关系”、知识图谱中的 “从属关系”、分子结构中的 “化学键” |
| 全局属性（Global/Master Node Attributes） | 整个图的属性信息，描述图的整体特征                 | 图的节点数量、边数量、最长路径长度、图的类型（如无向图、有向图） |

#### 2. 图的类型（Types of Graph）

- **无向图（Undirected Graph）**：边无方向，即边 (u,v) 与边 (v,u) 等价，如社交网络中的双向好友关系。
- **有向图（Directed Graph）**：边有方向，即边 (u,v) 表示从 u 到 v 的关系，与边 (v,u) 不同，如万维网中的超链接（从当前网页指向目标网页）。
- **加权图（Weighted Graph）**：边携带权重信息，如交通网络中边的权重表示两地距离或通行时间。
- **属性图（Attributed Graph）**：节点和 / 或边携带属性信息，如知识图谱中节点属性为 “名称”“类型”，边属性为 “关系类型”。

### 图神经网络（Graph Neural Networks, GNNs）

GNNs 是专门用于处理图数据的神经网络，通过**消息传递（Message Passing）** 机制学习节点的表示向量，捕捉节点间的依赖关系和图的全局结构信息。

#### 1. GNN 的核心思想（Core Idea of GNNs）

传统神经网络（如 CNN、RNN）仅能处理欧几里得数据（如网格结构的图像、序列结构的文本），无法直接处理图这种非欧几里得数据（节点邻居数量不固定，无固定空间结构）。GNN 的核心是**将节点的局部邻居信息聚合到节点自身**，通过迭代更新节点表示，使最终的节点表示包含邻居和全局结构信息。

#### 2. 图卷积与消息传递（Graph Convolution & Message Passing）

图卷积是 GNN 的核心操作，本质是**消息传递**—— 每个节点通过聚合其邻居节点的信息（消息）来更新自身的表示，具体步骤如下：

1. **消息生成（Message Generation）**：对每个节点 u，其邻居节点 v 生成消息\(m_{v \to u}\)，消息通常由邻居节点 v 的表示\(h_v\)、边 (u,v) 的属性\(e_{u,v}\)以及节点 u 的当前表示\(h_u\)共同决定：

   

   \(m_{v \to u} = f(h_u, h_v, e_{u,v})\)

   

   其中 f (・) 为消息函数（如线性变换、MLP）。

2. **消息聚合（Message Aggregation）**：将节点 u 的所有邻居消息聚合为一个全局消息\(m_u\)，聚合方式通常为求和（Sum）、均值（Mean）、最大值（Max）或注意力加权求和（Attention Weighted Sum）：

   

   \(m_u = \text{Aggregate}(\{m_{v \to u} | v \in \mathcal{N}(u)\})\)

   

   其中

   \(\mathcal{N}(u)\)

   为节点 u 的邻居集合。

3. **节点更新（Node Update）**：结合节点 u 的当前表示\(h_u\)和聚合消息\(m_u\)，更新节点 u 的新表示\(h_u'\)：

   

   \(h_u' = g(h_u, m_u)\)

   

   其中 g (・) 为更新函数（如线性变换 + 激活函数、MLP）。

#### 3. 图的拉普拉斯分析（Laplacian Analysis of Graph）

图拉普拉斯矩阵（Graph Laplacian Matrix）是图信号处理和图卷积的数学基础，用于描述图的结构特性和信号的平滑性。

- **图拉普拉斯矩阵的定义**：设图的邻接矩阵为 A（A [u][v] 为边 (u,v) 的权重，无边则为 0），度矩阵为 D（D [u][u] 为节点 u 的度，即所有与 u 相连的边的权重和，非对角线元素为 0），则图拉普拉斯矩阵 L 定义为：

  

  \(L = D - A\)

- **拉普拉斯矩阵的特征分解**：对拉普拉斯矩阵 L 进行特征分解，得到特征值\(\lambda_i\)和对应的特征向量\(u_i\)：

  

  \(L u_i = \lambda_i u_i\)

  

  - 特征值\(\lambda_i\)反映图的结构特性：λ=0 对应图的连通分量（若图连通，仅一个 λ=0），λ 越小表示对应特征向量的信号在图上越平滑（变化小），λ 越大表示信号变化越剧烈。
  - （图中展示不同特征值对应的特征向量可视化：λ=0.00 时信号平滑，λ=1.49 时信号变化剧烈，标注 “Low frequency”（低频，平滑信号）和 “High frequency”（高频，剧烈变化信号））

#### 4. 图傅里叶变换（Graph Fourier Transform）

图傅里叶变换是将图信号从空间域转换到谱域的工具，类比于传统信号处理的傅里叶变换，利用拉普拉斯矩阵的特征分解实现。

- **图傅里叶变换公式**：

  1. **信号分解（Spectral Domain Transformation）**：将空间域信号 f（节点表示向量）转换为谱域信号\(\hat{f}\)（特征系数向量）：

     

     \(\hat{f} = U^T f\)

     

     其中 U 是拉普拉斯矩阵 L 的特征向量矩阵（每一列是一个特征向量

     \(u_i\)

     ），

     \(\hat{f}_i = u_i^T f\)

     是信号 f 在特征向量

     \(u_i\)

     上的投影系数。

  2. **信号重构（Spatial Domain Reconstruction）**：将谱域信号\(\hat{f}\)转换回空间域信号 f：

     

     \(f = U \hat{f} = \sum_{i=0}^{N-1} \hat{f}_i \cdot u_i\)

     

     其中 N 为节点数量，重构过程是将信号分解为不同频率（特征值 λ_i）的分量之和。

- **意义**：图傅里叶变换为图卷积提供了谱域视角 —— 图卷积可在谱域中表示为信号与滤波器的点积

## 14.pdf 第 15 页（Basic Concept of Graph and GNN - 图与图神经网络基础）

### 图的基本概念（Basic Concepts of Graph）

图（Graph）是描述实体间关系的非欧几里得数据结构，由**节点（Vertices/Nodes）** 和**边（Edges）** 构成，广泛用于建模社交网络、知识图谱、分子结构等复杂关联数据。

#### 1. 图的核心组成

| 组成要素                          | 定义                                                         | 示例                                                         |
| --------------------------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| **节点（Node/Vertex, V）**        | 图中的实体单元，可携带属性信息（如特征向量）                 | 社交网络中的用户、知识图谱中的 “概念”、分子中的 “原子”       |
| **边（Edge, E）**                 | 连接节点的关系载体，可标注方向（有向 / 无向）、权重（关系强度） | 社交网络的 “好友关系”（无向）、网页的 “超链接”（有向）、交通网络的 “道路距离”（加权） |
| **全局属性（Global Attributes）** | 描述图整体特征的信息                                         | 图的节点总数、边总数、最长路径长度、连通分量数量             |

#### 2. 常见图类型

- **无向图（Undirected Graph）**：边无方向，如边 (u,v) 与边 (v,u) 等价（例：社交网络双向好友）。
- **有向图（Directed Graph）**：边有方向，如边 (u,v) 表示 “u 指向 v”（例：微博关注关系）。
- **加权图（Weighted Graph）**：边附带数值权重，如边权重表示 “距离”“流量”（例：城市交通图）。
- **属性图（Attributed Graph）**：节点 / 边携带特征属性，如节点属性为 “用户年龄”，边属性为 “互动频率”（例：电商用户 - 商品交互图）。

### 图神经网络（Graph Neural Networks, GNNs）

GNNs 是专为图数据设计的深度学习模型，通过**消息传递（Message Passing）** 机制聚合节点邻居信息，学习包含结构关联的节点表示，解决传统神经网络无法处理非欧几里得数据的问题。

#### 1. GNN 的核心逻辑：消息传递

消息传递是 GNN 的核心操作，本质是 “节点通过聚合邻居信息更新自身表示”，具体分三步：

1. **消息生成（Message Generation）**：邻居节点 v 向中心节点 u 传递消息，消息由邻居属性、边属性共同决定：

   

   \(m_{v \to u} = f(h_u, h_v, e_{u,v})\)

   

   （

   \(h_u\)

   ：中心节点当前表示；

   \(h_v\)

   ：邻居节点表示；

   \(e_{u,v}\)

   ：边属性；

   f

   ：消息函数，如线性变换、MLP）

2. **消息聚合（Message Aggregation）**：中心节点 u 整合所有邻居消息，常用聚合方式有求和（Sum）、均值（Mean）、最大值（Max）或注意力加权（Attention）：

   

   \(m_u = \text{Aggregate}(\{m_{v \to u} | v \in \mathcal{N}(u)\})\)

   

   （

   \(\mathcal{N}(u)\)

   ：节点 u 的邻居集合）

3. **节点更新（Node Update）**：结合自身旧表示与聚合消息，更新节点 u 的新表示：

   

   \(h_u' = g(h_u, m_u)\)

   

   （

   g

   ：更新函数，如 “线性变换 + ReLU”）

#### 2. 图拉普拉斯分析（Laplacian Analysis of Graph）

图拉普拉斯矩阵（Graph Laplacian Matrix）是图信号处理的数学基础，用于刻画图的结构特性与信号平滑性。

- **拉普拉斯矩阵定义**：设图的邻接矩阵为A（\(A_{u,v}\)为边 (u,v) 权重，无边则为 0），度矩阵为D（\(D_{u,u} = \sum_v A_{u,v}\)，非对角线为 0），则拉普拉斯矩阵\(L = D - A\)。
- **特征分解与意义**：对L进行特征分解\(L u_i = \lambda_i u_i\)（\(\lambda_i\)：特征值；\(u_i\)：特征向量）：
  - 特征值\(\lambda_i\)反映信号 “频率”：\(\lambda=0\)对应图的连通分量（连通图仅 1 个\(\lambda=0\)），\(\lambda\)越小，信号在图上越平滑（变化小）；\(\lambda\)越大，信号变化越剧烈。
  - （图中示例：\(\lambda=0.00\)时信号平滑，\(\lambda=1.49\)时信号剧烈波动，标注 “Low frequency”（低频）与 “High frequency”（高频））

#### 3. 图傅里叶变换（Graph Fourier Transform）

类比传统傅里叶变换，图傅里叶变换将图信号从 “空间域” 转换到 “谱域”，利用拉普拉斯矩阵的特征分解实现：

- **信号分解（谱域转换）**：空间域信号f（节点表示向量）→ 谱域信号\(\hat{f}\)（特征系数）：

  

  \(\hat{f} = U^T f\)

  

  （

  U

  ：拉普拉斯矩阵特征向量构成的矩阵，

  \(\hat{f}_i = u_i^T f\)

  为信号在特征向量

  \(u_i\)

  上的投影）

- **信号重构（空间域恢复）**：谱域信号\(\hat{f}\)→ 空间域信号f：

  

  \(f = U \hat{f} = \sum_{i=0}^{N-1} \hat{f}_i \cdot u_i\)

  

  （

  N

  ：节点数，重构即按特征值权重叠加不同频率的信号分量）

## 14.pdf 第 16 页（Object Detection - 目标检测）

### 目标检测的核心任务

目标检测是计算机视觉的核心任务，需同时完成 “**定位（Localization）**”（用边界框框出目标位置）和 “**分类（Classification）**”（判断目标类别），例如在自动驾驶场景中识别 “行人”“车辆” 并确定其位置。

### 目标检测算法分类

根据检测流程，主流算法分为**两阶段（Two-Stage）**、**单阶段（Single-Stage）** 和**无锚框（Anchor-Free）** 三类，核心差异在于是否生成 “候选区域（Region Proposal）”。

#### 1. 两阶段算法（Two-Stage Detectors）

特点：先生成候选区域（可能包含目标的区域），再对候选区域分类与边界框修正，精度高但速度较慢。

| 算法                    | 核心改进                                                     | 优势                                          | 劣势                                                         |
| ----------------------- | ------------------------------------------------------------ | --------------------------------------------- | ------------------------------------------------------------ |
| **R-CNN（Region-CNN）** | 1. 用传统方法（如 Selective Search）生成候选区域；2. 对每个候选区域独立用 CNN 提取特征；3. 分类（SVM）+ 边界框回归 | 开创两阶段范式，精度高于传统方法              | 1. 候选区域重复计算，速度极慢；2. 无法端到端训练             |
| **Fast R-CNN**          | 1. 先对整图用 CNN 提取共享特征图；2. 对候选区域用 “RoI Pooling” 裁剪特征；3. 端到端训练（分类 + 回归） | 共享特征计算，速度比 R-CNN 快 10 倍           | 候选区域仍依赖传统方法（如 Selective Search），速度瓶颈未完全解决 |
| **Faster R-CNN**        | 1. 用 “区域提议网络（RPN）” 替代传统方法，在共享特征图上生成候选区域；2. RPN 与检测网络共享特征，端到端训练 | 完全端到端，速度比 Fast R-CNN 快 5 倍，精度高 | 仍需候选区域处理，速度慢于单阶段算法                         |

- **关键概念：RoI Pooling vs. RoI Align**
  - RoI Pooling：将候选区域裁剪为固定尺寸（如 7×7），但存在 “量化误差”（候选区域坐标非整数时强制取整），影响定位精度。
  - RoI Align：用双线性插值保留候选区域的浮点坐标，消除量化误差，提升定位精度（常用于 Mask R-CNN 等高精度模型）。

#### 2. 单阶段算法（Single-Stage Detectors）

特点：无需生成候选区域，直接在特征图上密集预测类别与边界框，速度快但精度略低，适用于实时场景。

- **代表算法：YOLO（You Only Look Once）、SSD（Single Shot MultiBox Detector）**
  - **YOLO v1 核心逻辑**：将图像划分为 S×S 网格，每个网格预测 B 个边界框（x,y,w,h）和 1 个类别概率，直接输出最终检测结果，速度可达 45 FPS（帧 / 秒）。
  - **优势**：全局推理，对背景误检率低；速度快，支持实时检测。
  - **劣势**：小目标检测精度低（网格划分导致小目标易被忽略）；边界框预测误差较大。

#### 3. 无锚框算法（Anchor-Free Detectors）

特点：摒弃传统 “锚框（Anchor Box）”（预设的边界框模板），直接对特征点预测类别与边界框偏移，简化流程且适配任意目标尺寸。

- **代表算法：FCOS（Fully Convolutional One-Stage Object Detection）**
  - **核心逻辑**：对特征图每个像素，预测 “到目标边界的距离”（左、右、上、下）和类别概率，无需预设锚框，自适应目标大小。
  - **优势**：无锚框设计，减少超参数（如锚框数量、比例）；对小目标和密集目标检测更友好。
  - **劣势**：对边界模糊的目标（如遮挡目标）检测精度略低。

### 从区域提议到 RPN（Region Proposal to RPN）

Faster R-CNN 的核心创新是 “区域提议网络（RPN）”，其工作流程如下：

1. **输入**：共享特征图（如 CNN 输出的 64×64×256 特征图）。
2. **RPN 结构**：
   - 对特征图用 3×3 卷积提取局部特征；
   - 分两支预测：
     - 分类支：预测每个位置 “是否为目标”（2 类：前景 / 背景）；
     - 回归支：预测边界框偏移（4 个值：x,y,w,h 的偏移量）。
3. **锚框生成**：在特征图每个位置预设 k 个锚框（如 3 种尺度 ×3 种比例 = 9 个锚框），RPN 基于锚框预测修正后的候选区域。
4. **输出**：筛选出置信度高的候选区域（如 128 个），送入后续检测网络。

## 14.pdf 第 17 页（Evaluating Object Detectors - 目标检测评估指标）

### 核心评估指标

目标检测的评估需同时考虑 “分类准确性” 和 “定位准确性”，常用指标包括**IoU**、**Precision-Recall 曲线**、**AP（Average Precision）** 和**mAP（mean AP）**。

#### 1. IoU（Intersection over Union，交并比）

- **定义**：衡量预测边界框（Predicted Bbox）与真实边界框（Ground Truth Bbox）的重叠程度，计算公式为：

  \(IoU = \frac{\text{Area of Intersection}}{\text{Area of Union}}\)

- **意义**：IoU∈[0,1]，值越大表示重叠度越高，定位越准确。

- **常用阈值**：IoU>0.5 时，认为检测结果 “可接受”；IoU>0.75 时，认为定位精度高（COCO 数据集标准）。

- **示例**：若预测框与真实框重叠区域面积为 100，合并区域面积为 200，则 IoU=100/200=0.5，判定为 “有效检测”。

#### 2. 精确率（Precision）与召回率（Recall）

- **精确率（Precision）**：预测为正类的样本中，实际为正类的比例，衡量 “避免误检” 的能力：

  \(\text{Precision} = \frac{\text{TP}}{\text{TP} + \text{FP}}\)

  （TP：真阳性，正确检测到目标；FP：假阳性，误将背景检测为目标）

- **召回率（Recall）**：实际为正类的样本中，被正确预测的比例，衡量 “避免漏检” 的能力：

  \(\text{Recall} = \frac{\text{TP}}{\text{TP} + \text{FN}}\)

  （FN：假阴性，未检测到实际目标）

- **权衡关系**：精确率与召回率呈负相关（如提高阈值会减少 FP 但增加 FN，提升 Precision 但降低 Recall），需通过 “Precision-Recall 曲线” 综合评估。

#### 3. AP（Average Precision）与 mAP

- **AP 定义**：Precision-Recall 曲线下的面积，综合衡量不同召回率下的精确率，取值范围 [0,1]，值越大表示检测性能越好。
  - **计算步骤**：
    1. 按预测置信度从高到低排序所有检测结果；
    2. 逐个计算每个结果对应的 Precision 和 Recall；
    3. 对 Precision 曲线进行 “插值”（如 11 点插值法、积分法），计算曲线下面积即为 AP。
- **mAP 定义**：所有类别的 AP 平均值，衡量算法在整个数据集上的综合性能（如 COCO 数据集包含 80 个类别，mAP 为 80 个 AP 的均值）。
  - **示例**：若 “狗” 类 AP=0.86，“猫” 类 AP=0.82，则 mAP=(0.86+0.82)/2=0.84。

### 后处理技术：非极大值抑制（NMS）

目标检测会输出多个重叠的预测框（对应同一目标），需用 NMS 筛选出最优框，步骤如下：

1. 按预测置信度从高到低排序所有预测框；
2. 保留置信度最高的框作为 “基准框”，删除所有与基准框 IoU > 阈值（如 0.5）的重叠框；
3. 从剩余框中重复步骤 2，直至无重叠框残留。

- **作用**：消除重复检测，保留最优边界框，提升检测结果的清晰度。
- **注意**：NMS 仅对同一类别生效（不同类别即使重叠也不删除）。

### 评估示例

（图中展示检测结果与真实结果对比）

- **输入**：图像中包含 1 只狗，预测结果有 2 个框：框 1（P (dog)=0.9，IoU=0.8）、框 2（P (dog)=0.75，IoU=0.7）。
- **NMS 处理**：保留框 1（置信度高），删除框 2（与框 1 IoU=0.6>0.5）。
- **AP 计算**：若该类别的 Precision-Recall 曲线下面积为 0.86，则该类 AP=0.86。

## 14.pdf 第 18 页（Quiz Explanation 1 - 测验解析 1：MNIST 数据集特征提取与分类）

### 测验任务

基于 MNIST 手写数字数据集（0-9 共 10 类，28×28 灰度图像），完成 “特征提取（PCA/NMF）→ 可视化 → 分类（Softmax/SVM）” 全流程，并分析性能。

### 核心知识点与注意事项

#### 1. 数据泄露避免（Data Leakage Prevention）

- **关键原则**：仅用训练集（Training Data）拟合模型（PCA、分类器），测试集（Test Data）仅用于评估性能，禁止用测试集参与模型训练。

  - **错误做法**：将训练集 + 测试集合并后做 PCA，导致测试集信息提前泄露，评估结果偏乐观。

  - **正确流程**：

    1. 加载数据：\(x_{train}\)（训练图像）、\(y_{train}\)（训练标签）、\(x_{test}\)（测试图像）、\(y_{test}\)（测试标签）；

    2. 图像展平：将 28×28 图像转为 784 维向量（\(x_{train\_flatten}\)、\(x_{test\_flatten}\)）；

    3. PCA 拟合与变换：用\(x_{train\_flatten}\)训练 PCA，再分别变换训练集和测试集：

       

       \(estimator = PCA(n\_components=20)\)

       

       \(x_{train\_pca} = estimator.fit_transform(x_{train\_flatten})\)

       

       \(x_{test\_pca} = estimator.transform(x_{test\_flatten})\)

#### 2. 分类模型实现与性能对比

- **模型 1：Softmax 回归**

  - **核心逻辑**：将 PCA 降维后的特征输入 Softmax 函数，预测每个类别的概率，损失函数为交叉熵。
  - **测试准确率**：88.05%（简单模型，对非线性特征拟合能力弱）。

- **模型 2：支持向量机（SVM）**

  - **核心逻辑**：用 “StandardScaler” 标准化特征（消除量纲影响），再用 SVM 分类（核函数为 RBF，gamma='auto'）。

  - **代码示例**：

    python

    

    运行

    

    

    

    

    ```python
    from sklearn.pipeline import make_pipeline
    from sklearn.preprocessing import StandardScaler
    from sklearn.svm import SVC
    
    # 构建模型 pipeline（标准化 + SVM）
    clf = make_pipeline(StandardScaler(), SVC(gamma='auto'))
    # 训练模型
    clf.fit(x_train_pca, y_train)
    # 测试预测
    y_pred_test = clf.predict(x_test_pca)
    # 计算准确率
    correct_cnt = sum(y_pred_test == y_test)
    acc_test = correct_cnt / len(y_test)
    print(acc_test)  # 输出：97.72%
    ```

    

  - **性能分析**：SVM 准确率远高于 Softmax 回归，因 SVM 能捕捉特征间的非线性关系，对高维数据分类更鲁棒。

#### 3. 特征可视化（2D 散点图）

- **目标**：将 PCA 降维后的前 2 个主成分（PC1、PC2）可视化，用不同颜色区分类别，观察数据分布。

- **代码示例**：

  python

  

  运行

  

  

  

  

  ```python
  import matplotlib.pyplot as plt
  import numpy as np
  
  # 创建画布
  fig = plt.figure(figsize=(8, 6))
  # 筛选标签为0、1、2的样本索引
  idx_0 = np.squeeze(np.argwhere(y_train == 0))
  idx_1 = np.squeeze(np.argwhere(y_train == 1))
  idx_2 = np.squeeze(np.argwhere(y_train == 2))
  # 绘制散点图（不同颜色对应不同类别）
  plt.scatter(x_train_pca[idx_0, 0], x_train_pca[idx_0, 1], c='red', label='0')
  plt.scatter(x_train_pca[idx_1, 0], x_train_pca[idx_1, 1], c='blue', label='1')
  plt.scatter(x_train_pca[idx_2, 0], x_train_pca[idx_2, 1], c='green', label='2')
  # 添加标签与图例
  plt.xlabel('PC1')
  plt.ylabel('PC2')
  plt.legend()
  plt.show()
  ```

  

- **可视化结果**：标签 0、1、2 的样本在 2D 空间中形成相对独立的簇，说明 PCA 有效保留了类别区分信息。

#### 4. 主成分数量对性能的影响

- **结论**：主成分数量越多，保留的原始信息越完整，分类准确率越高（但超过一定数量后，准确率趋于饱和，且增加计算成本）。
  - 示例：当 n_components=10 时，SVM 测试准确率约 95%；n_components=20 时，准确率提升至 97.72%；n_components=50 时，准确率接近 98%（饱和）。

## 14.pdf 第 19 页（Quiz Explanation 2 - 测验解析 2：双分支神经网络反向传播）

### 测验任务

给定**双分支神经网络（Siamese Network）** 结构（用于相似度匹配，如人脸验证），推导损失函数J对共享权重\(W_1\)的偏导数\(\frac{\partial J}{\partial W_1}\)，并写出参数更新公式。

### 网络结构与公式定义

#### 1. 网络流程（单样本i）

- **分支 1**：输入\(x_1^{(i)} \to\) 线性变换\(z_1^{(i)} = W_1 x_1^{(i)} + b_1 \to\) ReLU 激活\(a_1^{(i)} = \text{ReLU}(z_1^{(i)})\)
- **分支 2**：输入\(x_2^{(i)} \to\) 线性变换\(z_2^{(i)} = W_1 x_2^{(i)} + b_1 \to\) ReLU 激活\(a_2^{(i)} = \text{ReLU}(z_2^{(i)})\)
- **特征融合**：\(a^{(i)} = a_1^{(i)} - a_2^{(i)}\)（计算两分支特征差）
- **输出层**：线性变换\(z_3^{(i)} = W_2 a^{(i)} + b_2 \to\) Sigmoid 激活\(\hat{y}^{(i)} = \sigma(z_3^{(i)}) = \frac{1}{1+e^{-z_3^{(i)}}}\)（预测相似度，\(\hat{y}^{(i)}\)接近 1 表示两输入相似）
- **损失函数**：
  - 单样本损失：\(L^{(i)} = -[y^{(i)} \log \hat{y}^{(i)} + (1-y^{(i)}) \log (1-\hat{y}^{(i)})]\)（二元交叉熵，\(y^{(i)}=1\)表示相似，\(y^{(i)}=0\)表示不相似）
  - 总损失：\(J = -\frac{1}{m} \sum_{i=1}^m L^{(i)}\)（m为样本数量）

### 偏导数推导（链式法则）

核心思路：从总损失J反向追溯至\(W_1\)，逐层计算梯度，最终整合为\(\frac{\partial J}{\partial W_1}\)。

#### 1. 步骤 1：J对\(L^{(i)}\)的偏导数

由\(J = -\frac{1}{m} \sum_{i=1}^m L^{(i)}\)，根据求和求导法则：

\(\frac{\partial J}{\partial L^{(i)}} = -\frac{1}{m}\)

#### 2. 步骤 2：\(L^{(i)}\)对\(\hat{y}^{(i)}\)的偏导数

对\(L^{(i)} = -[y^{(i)} \log \hat{y}^{(i)} + (1-y^{(i)}) \log (1-\hat{y}^{(i)})]\)求导：

\(\frac{\partial L^{(i)}}{\partial \hat{y}^{(i)}} = -\left( \frac{y^{(i)}}{\hat{y}^{(i)}} - \frac{1-y^{(i)}}{1-\hat{y}^{(i)}} \right)\)

#### 3. 步骤 3：\(\hat{y}^{(i)}\)对\(z_3^{(i)}\)的偏导数

由\(\hat{y}^{(i)} = \sigma(z_3^{(i)})\)，Sigmoid 函数导数特性为\(\sigma'(z) = \sigma(z)(1-\sigma(z))\)，因此：

\(\frac{\partial \hat{y}^{(i)}}{\partial z_3^{(i)}} = \hat{y}^{(i)} (1 - \hat{y}^{(i)})\)

结合步骤 2 和 3，由链式法则得：

\(\frac{\partial L^{(i)}}{\partial z_3^{(i)}} = \frac{\partial L^{(i)}}{\partial \hat{y}^{(i)}} \cdot \frac{\partial \hat{y}^{(i)}}{\partial z_3^{(i)}} = \hat{y}^{(i)} - y^{(i)}\)（化简后结果，便于计算）

#### 4. 步骤 4：\(z_3^{(i)}\)对\(a^{(i)}\)的偏导数

由\(z_3^{(i)} = W_2 a^{(i)} + b_2\)（线性变换），对\(a^{(i)}\)求导得：

\(\frac{\partial z_3^{(i)}}{\partial a^{(i)}} = W_2\)（\(W_2\)为权重矩阵，导数即矩阵本身）

#### 5. 步骤 5：\(a^{(i)}\)对\(a_1^{(i)}\)和\(a_2^{(i)}\)的偏导数

由\(a^{(i)} = a_1^{(i)} - a_2^{(i)}\)，求导得：

\(\frac{\partial a^{(i)}}{\partial a_1^{(i)}} = 1\)，\(\frac{\partial a^{(i)}}{\partial a_2^{(i)}} = -1\)

#### 6. 步骤 6：\(a_1^{(i)}/a_2^{(i)}\)对\(z_1^{(i)}/z_2^{(i)}\)的偏导数

由\(a_1^{(i)} = \text{ReLU}(z_1^{(i)})\)，ReLU 导数特性为\(\text{ReLU}'(z) = 1\)（\(z>0\)）或0（\(z \leq 0\)），因此：

\(\frac{\partial a_1^{(i)}}{\partial z_1^{(i)}} = \begin{cases} 1 & z_1^{(i)} > 0 \\ 0 & z_1^{(i)} \leq 0 \end{cases}\)，同理\(\frac{\partial a_2^{(i)}}{\partial z_2^{(i)}} = \begin{cases} 1 & z_2^{(i)} > 0 \\ 0 & z_2^{(i)} \leq 0 \end{cases}\)

#### 7. 步骤 7：\(z_1^{(i)}/z_2^{(i)}\)对\(W_1\)的偏导数

由\(z_1^{(i)} = W_1 x_1^{(i)} + b_1\)（线性变换，共享\(W_1\)），对\(W_1\)求导得：

\(\frac{\partial z_1^{(i)}}{\partial W_1} = x_1^{(i)} x_1^{(i)T}\)（向量外积，因\(W_1\)为矩阵，输入\(x_1^{(i)}\)为向量，导数为外积形式），同理\(\frac{\partial z_2^{(i)}}{\partial W_1} = x_2^{(i)} x_2^{(i)T}\)

### 整合偏导数与参数更新

#### 1. 总偏导数\(\frac{\partial J}{\partial W_1}\)

将上述步骤按链式法则串联，结合所有样本求和，最终得：

\(\frac{\partial J}{\partial W_1} = \frac{1}{m} \sum_{i=1}^m \left[ (\hat{y}^{(i)} - y^{(i)}) \cdot W_2^T \cdot \left( \frac{\partial a_1^{(i)}}{\partial z_1^{(i)}} \cdot x_1^{(i)} x_1^{(i)T} - \frac{\partial a_2^{(i)}}{\partial z_2^{(i)}} \cdot x_2^{(i)} x_2^{(i)T} \right) \right]\)

- **说明**：\(W_2^T\)为\(W_2\)的转置（保证维度匹配）；外积\(x x^T\)确保导数维度与\(W_1\)一致（若\(W_1\)为\(d \times d\)矩阵，x为d维向量，则\(x x^T\)为\(d \times d\)矩阵）。

#### 2. 参数更新公式

用梯度下降法更新\(W_1\)，学习率为\(\alpha\)（控制步长）：

\(W_1 = W_1 - \alpha \cdot \frac{\partial J}{\partial W_1}\)

- **注意**：\(\alpha\)需合理选择（过大会导致震荡不收敛，过小会导致收敛过慢），常用值为 0.001、0.0001。

## 14.pdf 第 20 页（Final Term Exam Demo - 期末考试说明与示例）

### 期末考试基本信息

| 考试信息 | 具体内容                                                     |
| -------- | ------------------------------------------------------------ |
| 考试时间 | 2024-12-30（周一）09:00~11:00（2 小时）                      |
| 考试地点 | 六教 - 6A209                                                 |
| 试卷构成 | 1. 判断题：10 题 ×2 分 = 20 分；2. 多选题：6 题 ×5 分 = 30 分；3. 问答题 & 计算题：5 题 ×10 分 = 50 分；（总分 100 分） |
| 考试范围 | 课程所有 PPT 内容（含嘉宾讲座、期末项目）                    |
| 考试规则 | 1. 开卷考试，仅允许使用纸质参考资料（如讲义、笔记）；2. 禁止使用电子设备（如手机、电脑、计算器除外）；3. 必须携带计算器（用于矩阵计算、导数求解等）。 |

### 题型示例与解析

#### 1. 判断题（True or False）

- **例题 1**：增加深度学习模型的参数数量，预测的准确率和泛化能力都会提升，因为模型能更好地拟合数据。（2 分）

  **答案**：False（错误）

  **解析**：参数过多会导致 “过拟合”（训练集准确率高，但测试集准确率低），泛化能力下降；需通过正则化（如 L2 正则、Dropout）或数据增强避免过拟合。

- **例题 2**：K-means 聚类在给定数据集上不总是收敛到全局最小值。（2 分）

  **答案**：True（正确）

  **解析**：K-means 的目标函数（簇内平方和）是非凸的，初始簇中心的选择会影响最终结果，可能收敛到局部最小值，需多次随机初始化或用 K-means++ 优化初始簇中心。

- **例题 3**：在 RNN 中，通常对不同时间步的隐藏状态更新使用不同的权重。（2 分）

  **答案**：False（错误）

  **解析**：RNN 的核心是 “参数共享”，不同时间步的隐藏状态更新使用相同的权重\(W_h\)，减少参数数量并捕捉序列的时序规律；若使用不同权重，会导致参数爆炸且无法泛化到变长序列。

- **例题 4**：某项目组在二分类任务中（50 个正样本，5000 个负样本）取得 98% 的分类准确率，其成果可接受。（2 分）

  **答案**：False（错误）

  **解析**：数据严重不平衡（负样本占比 99%），即使模型全部预测为负样本，准确率也可达 99%（5000/(50+5000)≈99%），98% 的准确率低于随机猜测，说明模型无实际效果，需用 F1 分数、AUC 等平衡指标评估。

#### 2. 多选题（Multiple Choices）

- **例题 1**：下列关于目标检测算法评估的说法正确的是（）。（5 分）

  A. 对于不同预测类别的边界框，若 IoU 超过阈值，NMS 会删除得分低的框；

  B. NMS 不擅长处理高度重叠的目标；

  C. mAP 中的 “mean” 指对所有类别的 AP 取平均；

  D. 计算 mAP 时，选择更大的 IoU 阈值通常会导致 mAP 更高。

  **答案**：B、C

  **解析**：

  - A 错误：NMS 仅对同一类别生效，不同类别即使重叠也不删除；
  - B 正确：高度重叠目标的 IoU 超过阈值，NMS 会误删正确框；
  - C 正确：mAP（mean Average Precision）即所有类别 AP 的平均值；
  - D 错误：IoU 阈值越大，对定位精度要求越高，Precision 和 Recall 越低，mAP 通常降低。

- **例题 2**：下列目标检测算法中，（）使用网络回归初始边界框（候选区域）的变换参数，最终得到输出边界框。（5 分）

  A. FCOS；B. Fast R-CNN；C. Faster R-CNN；D. YOLO v1；E. R-CNN

  **答案**：B、C、E

  **解析**：

  - A 错误：FCOS 是 Anchor-Free 算法，直接预测边界框坐标，无初始边界框；
  - B 正确：Fast R-CNN 对候选区域用 RoI Pooling 提取特征，回归边界框变换参数；
  - C 正确：Faster R-CNN 用 RPN 生成候选区域，再回归变换参数；
  - D 错误：YOLO v1 直接预测边界框坐标，无初始边界框；
  - E 正确：R-CNN 对候选区域用 CNN 提取特征，用 SVM 分类 + 线性回归修正边界框。

## 14.pdf 第 21 页（Final Term Exam Demo - 问答题与计算题示例）

### 问答题示例（10 分 / 题）

#### 例题 1：神经网络参数初始化问题

**问题**：若将神经网络的参数初始化为相同值或全零，这种 “对称初始化” 是否可行？请分别解释全零初始化和相同值初始化的影响。

**参考答案**：

这种对称初始化不可行，具体影响如下：

1. **全零初始化（All-Zero Initialization）**（5 分）
   - 影响：所有权重初始化为 0 时，前向传播中每个神经元的输出均为 0（因输入加权和为 0，激活后仍为 0）；反向传播时，权重的梯度均为 0（导数链式传递后结果为 0），导致权重无法更新，模型始终处于 “死区”，无法学习任何特征。
   - 结论：全零初始化会导致 “梯度消失”，模型无法训练。
2. **相同值初始化（Identical Initialization）**（5 分）
   - 影响：若同一层神经元的权重初始化为相同值（如均为 0.1），前向传播中同一层所有神经元的输出相同（输入加权和相同，激活后输出一致）；反向传播时，同一层权重的梯度相同，更新后仍保持相同值，导致神经元 “功能冗余”—— 同一层神经元等价于 1 个神经元，失去并行计算和特征多样性捕捉能力，网络性能大幅下降（退化）。
   - 结论：相同值初始化会导致 “对称权重问题”，网络退化，无法学习复杂特征。

**总结**：需采用非对称初始化（如 Xavier 初始化、He 初始化），使权重服从随机分布，避免对称问题和梯度消失。

#### 例题 2：自动驾驶目标检测算法选择

**问题**：假设你需为自动驾驶系统设计目标检测模块，对比 Faster R-CNN、YOLO、FCOS 三种算法，你会选择哪种？请说明理由。

**参考答案**：

选择**YOLO**或**Faster R-CNN**，具体取决于场景需求，理由如下：

1. **选择 YOLO 的理由**（适用于实时性优先场景）（5 分）
   - YOLO 是单阶段算法，无需候选区域处理，速度快（如 YOLO v5 可达 150 FPS），能满足自动驾驶 “实时响应” 需求 —— 道路场景中车辆、行人位置动态变化，需模型在 100ms 内输出检测结果，避免事故。
   - 劣势：小目标检测精度略低，但可通过多尺度特征融合（如 YOLO v7 的 PANet 结构）优化，满足自动驾驶对 “车辆、行人” 等中大型目标的检测需求。
2. **选择 Faster R-CNN 的理由**（适用于精度优先场景）（5 分）
   - Faster R-CNN 是两阶段算法，通过 RPN 生成高质量候选区域，定位精度高（mAP 高于 YOLO），能准确检测 “交通标志、护栏” 等小目标，避免因小目标漏检导致的安全风险。
   - 劣势：速度慢（约 10 FPS），需搭配硬件加速（如 GPU、FPGA）才能满足实时需求，适合对精度要求极高的场景（如高速公路自动驾驶）。
3. **不选择 FCOS 的理由**（2 分，补充说明）
   - FCOS 是 Anchor-Free 算法，对遮挡目标检测精度低（如车辆拥堵场景中，部分车身被遮挡时，边界框预测误差大），而自动驾驶中遮挡是常见场景，易导致误检或漏检，安全性不足。

#### 例题 3：R-CNN 与 Faster R-CNN 候选区域方法差异

**问题**：R-CNN 和 Faster R-CNN 在候选区域生成方法上的核心差异是什么？该差异对算法性能有何影响？

**参考答案**：

1. **核心差异**（5 分）
   - R-CNN：使用传统计算机视觉方法（如 Selective Search）生成候选区域 —— 通过图像分割、纹理分析等方式，生成约 2000 个候选区域，再送入 CNN 提取特征。
   - Faster R-CNN：使用 “区域提议网络（RPN）” 生成候选区域 —— 在 CNN 提取的共享特征图上，通过滑动窗口预测 “前景 / 背景” 和边界框偏移，生成约 300 个候选区域，无需传统方法。
2. **对性能的影响**（5 分）
   - **速度影响**：R-CNN 的候选区域生成依赖传统方法，耗时占总检测时间的 90%；Faster R-CNN 的 RPN 与检测网络共享特征，候选区域生成速度快，总检测速度比 R-CNN 快 100 倍，实现端到端训练。
   - **精度影响**：RPN 基于深度学习预测候选区域，能自适应图像内容（如复杂背景下筛选高质量候选区域），候选区域质量高于传统方法，因此 Faster R-CNN 的检测精度（mAP）比 R-CNN 高 5%~10%。

**总结**：Faster R-CNN 用 RPN 替代传统方法，解决了 R-CNN 的速度瓶颈，同时提升了精度，是两阶段算法的里程碑。

### 计算题示例（10 分 / 题）

#### 例题：PCA 降维计算

**问题**：给定 5 个 2 维样本：\(x_1=(1,2)\)，\(x_2=(2,4)\)，\(x_3=(3,6)\)，\(x_4=(4,8)\)，\(x_5=(5,10)\)，请用 PCA 将其降维到 1 维，写出主成分方向和降维后的样本表示。

**参考答案**：

PCA 降维步骤如下：

1. **步骤 1：数据中心化（均值减法）**（2 分）

   - 计算样本均值：\(\bar{x} = \left( \frac{1+2+3+4+5}{5}, \frac{2+4+6+8+10}{5} \right) = (3, 6)\)

   - 中心化样本：\(x_i' = x_i - \bar{x}\)

     

     \(x_1'=(-2,-4)\)

     ，

     \(x_2'=(-1,-2)\)

     ，

     \(x_3'=(0,0)\)

     ，

     \(x_4'=(1,2)\)

     ，

     \(x_5'=(2,4)\)

2. **步骤 2：计算协方差矩阵**（3 分）

   - 协方差矩阵公式：\(C = \frac{1}{n-1} X X^T\)（X为中心化样本构成的矩阵，\(n=5\)）
   - \(X = \begin{bmatrix} -2 & -1 & 0 & 1 & 2 \\ -4 & -2 & 0 & 2 & 4 \end{bmatrix}\)
   - \(X X^T = \begin{bmatrix} (-2)^2+(-1)^2+0+1^2+2^2 & (-2)(-4)+(-1)(-2)+0+1×2+2×4 \\ (-4)(-2)+(-2)(-1)+0+2×1+4×2 & (-4)^2+(-2)^2+0+2^2+4^2 \end{bmatrix} = \begin{bmatrix} 10 & 20 \\ 20 & 40 \end{bmatrix}\)
   - 协方差矩阵：\(C = \frac{1}{5-1} \begin{bmatrix} 10 & 20 \\ 20 & 40 \end{bmatrix} = \begin{bmatrix} 2.5 & 5 \\ 5 & 10 \end{bmatrix}\)

3. **步骤 3：求解协方差矩阵的特征值与特征向量**（3 分）

   - 特征方程：\(\det(C - \lambda I) = 0\)

     

     \(\det\begin{bmatrix} 2.5-\lambda & 5 \\ 5 & 10-\lambda \end{bmatrix} = (2.5-\lambda)(10-\lambda) - 25 = 0\)

     

     展开得：

     \(\lambda^2 - 12.5\lambda = 0\)

     ，解得特征值

     \(\lambda_1=12.5\)

     （主特征值），

     \(\lambda_2=0\)

     。

   - 主特征向量（对应\(\lambda_1=12.5\)）：解\((C - 12.5I)e = 0\)

     

     \(\begin{bmatrix} -10 & 5 \\ 5 & -2.5 \end{bmatrix} \begin{bmatrix} e_1 \\ e_2 \end{bmatrix} = 0\)

     ，得

     \(-10e_1 +5e_2=0 \to e_2=2e_1\)

     

     取单位特征向量：

     \(e_1 = \frac{1}{\sqrt{1^2+2^2}} (1,2) = \left( \frac{1}{\sqrt{5}}, \frac{2}{\sqrt{5}} \right)\)

     （主成分方向）

4. **步骤 4：样本降维（投影到主成分方向）**（2 分）

   - 降维公式：\(x_i'' = e_1^T x_i'\)（投影到主成分方向）

     

     \(x_1'' = \left( \frac{1}{\sqrt{5}}, \frac{2}{\sqrt{5}} \right) \cdot (-2,-4) = \frac{-2 -8}{\sqrt{5}} = -2\sqrt{5}\)

     

     \(x_2'' = \frac{-1 -4}{\sqrt{5}} = -\sqrt{5}\)

     ，

     \(x_3''=0\)

     ，

     \(x_4''=\sqrt{5}\)

     ，

     \(x_5''=2\sqrt{5}\)

   - 降维后样本：\([-2\sqrt{5}, -\sqrt{5}, 0, \sqrt{5}, 2\sqrt{5}]\)（1 维表示）