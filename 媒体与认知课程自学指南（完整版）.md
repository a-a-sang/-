# 媒体与认知课程自学指南（完整版）

## 一、参考书籍核心定位与体系

围绕课程 8 份核心文档（5.pdf、6.pdf、7.pdf、9-1.pdf、2-1.pdf、2-2.pdf、4.pdf），构建 “理论奠基 + 实践落地 + 专项深化” 的三层自学体系，涵盖 6 本核心书籍：

| 书籍类型     | 书籍名称                                             | 核心定位                                                     | 适配文档重点          |
| ------------ | ---------------------------------------------------- | ------------------------------------------------------------ | --------------------- |
| 传统机器学习 | 《机器学习》（西瓜书）                               | 系统讲解传统机器学习理论（线性模型、SVM、聚类等），为深度学习打基础 | 2-1.pdf、4.pdf        |
| 深度学习理论 | 《深度学习》（花书）                                 | 深入剖析深度学习数学原理（反向传播、优化算法、模型架构），提升理论深度 | 5.pdf、6.pdf、9-1.pdf |
| 深度学习入门 | 《深度学习入门：基于 Python 的理论与实现》（鱼书 1） | 零基础入门深度学习，手工实现神经网络、CNN、RNN，理解底层逻辑 | 5.pdf、6.pdf、9-1.pdf |
| 自然语言处理 | 《自然语言处理入门》（鱼书 2）                       | 聚焦 NLP 任务（文本分类、序列建模），衔接 RNN/LSTM 与语言场景 | 9-1.pdf               |
| 深度学习框架 | 《深度学习框架：自制深度学习框架》（鱼书 3）         | 讲解深度学习框架核心组件（自动求导、计算图），理解框架底层运行机制 | 5.pdf、4.pdf          |
| 强化学习     | 《强化学习入门》（鱼书 4）                           | 补充强化学习理论（MDP、Q-Learning、策略梯度），适配序列决策与生成模型场景 | 6.pdf、9-1.pdf        |
| 深度学习实践 | 《动手学深度学习》（D2L）                            | 交互式代码实战（PyTorch/TensorFlow），覆盖 CNN、GNN、目标检测等工程实现 | 所有文档              |

## 二、各 Lecture 对应书籍章节（完整版）

### （一）Lecture 2：Feature Engineering-I（2-1.pdf）+ Supplement（2-2.pdf）

#### 主要内容

1.  **基础概念与 PCA**：介绍高维原始数据（如 MEG 脑成像、文档分类数据、高分辨率图像等）的特征工程需求，重点讲解主成分分析（PCA）—— 通过计算协方差矩阵的特征值和特征向量，将高维数据投影到低维子空间，最大化投影数据方差，实现降维、数据压缩、噪声去除等，还通过人脸识别、图像压缩案例说明其应用，同时指出 PCA 无法检测边缘、角点等人关注的特征。

2.  **传统特征检测**：讲解角点检测原理，包括 Harris 角点检测（通过计算图像梯度、协方差矩阵，基于特征值构造角点响应函数 R 实现角点检测，具有旋转不变性但无尺度不变性）；介绍尺度不变特征检测方法，如利用拉普拉斯滤波器选择特征尺度。

3.  **特征描述子**：详细阐述 SIFT（尺度不变特征变换），包括多尺度极值检测（构建高斯金字塔与差分金字塔）、关键点定位、方向分配、关键点描述子生成四个步骤，同时介绍 SURF（加速鲁棒特征，用盒滤波近似 SIFT 的 DOG，借助积分图像提速）、FAST（快速角点检测）、BRIEF（二进制特征描述子）、ORB（结合 FAST 与 BRIEF，免费替代专利的 SIFT/SURF）。

4.  **学习型特征提取**：介绍 LIFT（首个端到端可微的特征点处理架构，含检测、方向估计、特征描述）、SuperPoint（基于 FCN 的自监督兴趣点检测与描述）、LF-Net（多尺度 FCN 用于关键点定位、尺度和方向估计），通过渐进式学习、自监督学习等方式优化特征提取。

#### 文档核心内容

高维数据降维（PCA）、传统特征检测（Harris 角点、SIFT/SURF）、学习型特征提取（LIFT、SuperPoint、LoFTR）。

#### 对应书籍章节

| 书籍               | 对应章节                                                     | 核心作用                                                     |
| ------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 西瓜书             | 10.1 主成分分析（PCA）；11.1 特征选择与稀疏学习（传统特征筛选） | 1. 理解 PCA 的数学原理（协方差矩阵、特征值分解）；2. 掌握传统特征的统计筛选方法 |
| 花书               | 15.2 自编码器（非线性降维）；12.1 卷积神经网络（特征提取基础） | 1. 对比 PCA（线性）与自编码器（非线性）的降维差异；2. 理解 CNN 特征提取的层级性 |
| 鱼书 1（入门）     | 无直接对应章节（侧重深度学习，需结合西瓜书补充传统特征工程） | 辅助理解 “学习型特征与神经网络的关联”，为后续 LIFT、SuperPoint 铺垫 |
| 鱼书 3（框架）     | 3. 自动求导机制；4. 计算图构建                               | 理解 LIFT、SuperPoint 等学习型特征模型的反向传播实现依赖框架的自动求导能力 |
| 《动手学深度学习》 | 3.1 线性回归（PCA 数学基础：矩阵运算）；13.1 图像增广（特征鲁棒性）；13.2 自编码器 | 1. 用 PyTorch 实现 PCA 降维（MNIST 数据集），验证投影方差最大化；2. 实战图像增广，提升特征对旋转、噪声的鲁棒性；3. 实现简化版自编码器，对比 PCA 与自编码器的降维效果 |

#### 学习路径建议

1. 先学西瓜书 10.1 节（PCA 理论）→ 用《动手学深度学习》3.1 节代码实现 PCA→ 验证 2-1.pdf 中 “MEG 脑成像数据降维” 场景；
2. 学 2-2.pdf 中 LIFT、SuperPoint 模型→ 结合鱼书 3（框架）的自动求导章节，理解模型反向传播的工程实现→ 用《动手学深度学习》13.2 节代码复现简化版 SuperPoint。

### （二）Lecture 4：Feature Engineering-II（4.pdf）

#### 主要内容

1.  **特征工程回顾与应用场景**：回顾特征需具备抗数据方差、非冗余、类间区分性等特性，通过房价预测案例（浴室数量、房龄、房屋新旧等特征与房价的相关性）说明特征选择，介绍特征在分类、检测、推荐、识别等任务中的应用。

2.  **线性回归**：阐述线性回归模型公式$y^{(i)}=h_{\theta}(x^{(i)})=\theta^{T}x^{(i)}$，优化目标为最小化均方误差（LSE），提供闭式解$\theta^{*}=(X^{T}X)^{-1}X^{T}Y$与梯度下降两种求解方法，讲解梯度下降的学习率选择（过大会发散、过小收敛慢）、动态学习率（如线性衰减、指数衰减）及随机梯度下降（SGD，基于 mini-batch 计算梯度，提升效率），分析 GD/SGD 在凸 / 非凸损失函数中的优化效果及跳出局部最优的方法（动量、梯度噪声、批数据）。

3.  **二分类**：介绍支持向量机（SVM），通过寻找最大间隔线性分离器，将问题转化为最小化$\frac{1}{2}\|w\|_{2}^{2}$（满足$y^{(i)}(w^{T}x^{(i)}+b)\geq1$约束），讲解原始问题与对偶问题的转化、SMO（序列最小优化）算法求解对偶问题，引入核技巧（如多项式核、高斯核、Sigmoid 核）实现非线性分类；讲解逻辑回归，通过 Sigmoid 函数将线性输出映射到 \[0,1] 区间，基于极大似然估计构建损失函数，用梯度下降优化参数。

4.  **多分类**：介绍 Softmax 回归（逻辑回归的多分类扩展，通过 Softmax 函数将输出转化为类概率分布）、K-means 聚类（无监督聚类，通过迭代分配样本到最近聚类中心、更新聚类中心实现），对比监督与无监督多分类方法，提及高斯混合模型（GMM）等其他聚类方法。

#### 文档核心内容

线性回归（闭式解、梯度下降）、二分类（SVM、逻辑回归）、多分类（Softmax、K-means）。

#### 对应书籍章节

| 书籍               | 对应章节                                                     | 核心作用                                                     |
| ------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 西瓜书             | 3.2 线性回归；6.2 支持向量机；9.1 K 均值聚类                 | 1. 掌握线性回归的闭式解推导；2. 理解 SVM 的最大间隔原理；3. 掌握 K-means 的聚类逻辑 |
| 花书               | 5.1 线性模型；5.6 优化算法（梯度下降变种）；11.3 软 max 回归 | 1. 深化线性模型的概率解释；2. 理解动量、RMSProp 等优化算法的数学原理；3. 掌握 Softmax 的多分类概率建模 |
| 鱼书 1（入门）     | 3. 神经网络的数学基础（梯度计算）；4. 神经网络的学习（梯度下降实现）；5. 误差反向传播 | 1. 手工实现线性回归的梯度下降，理解学习率对收敛的影响；2. 用简单神经网络实现逻辑回归，衔接 Softmax 多分类 |
| 鱼书 3（框架）     | 2. 张量运算；5. 优化器实现（SGD、Adam）                      | 1. 理解线性回归、SVM 中的张量运算（如矩阵乘法）；2. 手动实现优化器，验证 4.pdf 中 “动态学习率” 的效果 |
| 《动手学深度学习》 | 3.2 线性回归从零实现；3.3 线性回归简洁实现；4. Softmax 回归；5. 多层感知机；10. K-means 聚类 | 1. 用 PyTorch 实现线性回归的 SGD 与批量梯度下降，对比效率；2. 实战 Softmax 回归（CIFAR-10 子集），验证交叉熵损失；3. 实现 K-means，对比 4.pdf 中 “聚类效果与标签匹配度” |

#### 学习路径建议

1. 学西瓜书 3.2 节（线性回归理论）→ 用鱼书 1（入门）4.1 节代码手动实现梯度下降→ 用《动手学深度学习》3.2 节对比框架实现效率；
2. 学 4.pdf 中 SVM 的最大间隔→ 结合花书 5.6 节（优化算法）→ 用《动手学深度学习》6.3 节代码复现 SVM，验证 “核技巧” 对非线性数据的分类效果；
3. 学 4.pdf 中 K-means→ 用《动手学深度学习》10.3 节代码实现，对比不同初始聚类中心对结果的影响。

### （三）Lecture 5：Deep Neural Networks（5.pdf）

#### 主要内容

1.  **AI 发展历程与深度学习基础**：梳理 AI 的爆发与寒冬阶段，从 1956 年达特茅斯会议诞生 AI，到深度学习推动的第三次爆发（如 AlphaGo 系列、自动驾驶、语音识别等应用），对比人类大脑（860 亿神经元、低功耗高效计算）与深度学习模型（大模型、大数据、高性能计算支撑）的结构与功能。

2.  **神经网络基础**：介绍 ANN、DNN、CNN、RNN 等概念，讲解感知机（神经网络的基础单元，含输入、权重、求和、非线性激活函数），常用激活函数（Sigmoid、Tanh、ReLU、ELU）及作用（引入非线性，使网络可近似复杂函数），构建单隐层与深度神经网络结构。

3.  **神经网络训练**：核心讲解反向传播（BP）算法，基于链式法则计算各层权重的梯度，结合梯度下降优化网络参数；分析训练难点（如非凸损失函数的局部最优、梯度消失 / 爆炸），介绍先进训练技术：自适应学习率（如线性衰减、指数衰减）、高级梯度下降算法（动量、RMSProp、Adam）、正则化（L1、L2、Dropout、早停）、批归一化（标准化激活值，加速训练、提升稳定性）、参数初始化（如 Xavier 初始化、He 初始化，避免梯度消失 / 爆炸）、超参数调优（网格搜索、随机搜索）。

4.  **DNN 规模与挑战**：展示当前 SOTA DNN 的规模（如 ResNet-1001、GPT-4 的 1.76 万亿参数），分析模型训练的计算资源消耗与碳排放问题，提及深度学习框架（如 PyTorch）在实践中的应用。

#### 文档核心内容

DNN 基础（感知机、激活函数）、反向传播（BP）、训练技术（批归一化、正则化、优化算法）、模型规模与算力需求。

#### 对应书籍章节

| 书籍               | 对应章节                                                     | 核心作用                                                     |
| ------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 西瓜书             | 5.3 神经网络（基础架构）；7.1 模型评估与选择（正则化）       | 1. 理解神经网络的层级结构；2. 掌握传统正则化（L1、L2）的原理 |
| 花书               | 6.1 深度前馈网络；6.5 反向传播；7.1 正则化；8.1 参数更新算法 | 1. 深入剖析 DNN 的反向传播数学推导；2. 理解批归一化、Dropout 的理论依据；3. 掌握 Adam 等优化算法的收敛性分析 |
| 鱼书 1（入门）     | 5. 误差反向传播（BP 手动实现）；6. 与学习相关的技巧（权重初始化、批归一化）；7. 卷积神经网络（基础） | 1. 手动推导 2 层 DNN 的反向传播，验证链式法则应用；2. 实现批归一化层，验证 5.pdf 中 “缓解梯度消失” 的效果；3. 理解激活函数（ReLU、Sigmoid）的选择逻辑 |
| 鱼书 3（框架）     | 1. 框架核心组件；3. 自动求导；6. 批处理与并行计算            | 1. 理解 DNN 训练依赖的框架组件（计算图、自动求导）；2. 实现批处理，验证 5.pdf 中 “高 - performance computing” 的算力需求 |
| 鱼书 4（强化学习） | 无直接对应章节（强化学习侧重序列决策，可辅助理解 “模型优化的奖励机制”） | 辅助理解 5.pdf 中 “损失函数优化” 与强化学习 “奖励函数优化” 的异同 |
| 《动手学深度学习》 | 5. 多层感知机；7. 优化算法；8. 批量归一化；9. 正则化；11. 模型选择与调优 | 1. 用 PyTorch 搭建 5 层 MLP，对比 “有无批归一化” 的训练稳定性；2. 实战 Adam、RMSProp，验证 5.pdf 中 “优化算法对收敛速度的提升”；3. 用网格搜索调优超参数，匹配 5.pdf 中 “Hyperparameters” 章节 |

#### 学习路径建议

1. 学 5.pdf 中感知机与激活函数→ 用鱼书 1（入门）3.1 节代码实现不同激活函数→ 对比 ReLU 与 Sigmoid 的梯度分布；
2. 学 5.pdf 中反向传播→ 结合花书 6.5 节推导→ 用鱼书 1（入门）5.3 节代码手动计算梯度→ 用《动手学深度学习》5.4 节验证框架自动求导结果；
3. 学 5.pdf 中批归一化、Dropout→ 用《动手学深度学习》8.3 节、9.1 节代码实现→ 对比 5.pdf 中 “ResNet 损失曲面” 的平滑效果。

### （四）Lecture 6：Convolutional Neural Networks - I（6.pdf）

1.  **CNN 核心动机与基础**：针对视觉数据（图像、视频）的空间结构特性，指出 MLP 将图像拉伸为向量丢失空间信息的缺陷，介绍 CNN 的核心优势 —— 利用卷积操作提取空间层次特征（局部连接、参数共享），回顾 CNN 发展历程（从 Hubel 和 Wiesel 发现视觉皮层细胞特性，到 Neocognitron、LeNet、AlexNet 等经典架构）。

2.  **CNN 基本构建块**：详细讲解卷积层（输入特征图与卷积核的滑动点积计算，涉及输入输出维度计算、 stride、padding、多通道卷积、批量卷积）、激活函数层（ReLU 等，引入非线性）、池化层（最大池化、平均池化、随机池化，降维、保留空间不变性）、全连接层（将卷积提取的特征映射为类别概率或回归值），说明各层的作用与协作方式（如 Conv→ReLU→Conv→ReLU→Pool 的经典组合）。

3.  **经典 CNN 架构**：逐一解析 AlexNet（2012 年 ImageNet 冠军，8 层架构，首次用 ReLU、数据增强、Dropout）、VGG（小卷积核（3×3）、深层数（16/19 层），提升特征提取能力）、GoogLeNet（引入 Inception 模块，并行多尺度卷积与池化，高效利用计算资源，22 层仅 500 万参数）、ResNet（引入残差连接，解决深度网络梯度消失问题，支持 1001 层训练，ILSVRC 2015 冠军），对比各架构的设计思路与性能。

4.  **生成模型**：介绍生成对抗网络（GAN），包括生成器（从随机噪声生成逼真样本）与判别器（区分真实与生成样本）的对抗训练机制，讲解 GAN 的目标函数（极小极大博弈）与训练流程；提及扩散模型（当前 SOTA 生成模型，基于扩散 - 逆扩散过程生成高质量样本，如 DALL-E、Stable Diffusion），对比 GAN 与扩散模型的优劣。

#### 文档核心内容

CNN 基础（卷积、池化）、经典架构（AlexNet、VGG、ResNet、GoogLeNet）、生成模型（GAN、扩散模型）。

#### 对应书籍章节

| 书籍               | 对应章节                                                     | 核心作用                                                     |
| ------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 西瓜书             | 无直接对应章节（侧重传统机器学习，可补充 “特征提取的统计方法”） | 辅助理解 CNN 特征提取与传统统计特征的差异                    |
| 花书               | 12.1 卷积神经网络；12.4 生成对抗网络；15.5 深度生成模型      | 1. 深入剖析卷积运算的数学本质（局部连接、参数共享）；2. 理解 GAN 的对抗训练博弈论基础；3. 掌握扩散模型的非平衡热力学原理 |
| 鱼书 1（入门）     | 7. 卷积神经网络（卷积层、池化层实现）；8. 深度学习的应用（图像分类）；10. 生成对抗网络 | 1. 手动实现卷积层（滑动窗口、多通道），验证 6.pdf 中 “参数共享减少参数量” 的效果；2. 搭建简单 CNN（LeNet），对比 6.pdf 中 AlexNet 的架构创新；3. 实现 GAN 生成 MNIST 图像，理解对抗训练逻辑 |
| 鱼书 4（强化学习） | 6. 策略梯度；7. 深度强化学习（DQN）                          | 辅助理解生成模型（如 GAN）中 “生成器策略优化” 与强化学习 “策略梯度” 的关联 |
| 《动手学深度学习》 | 11. 卷积神经网络（经典架构实现）；16. 生成对抗网络；17. 扩散模型；18. 图像生成 | 1. 复现 AlexNet、VGG、ResNet，对比 6.pdf 中 “ImageNet 准确率曲线”；2. 实战 DCGAN、StyleGAN，验证 6.pdf 中 “GAN 生成高质量图像” 的效果；3. 实现简化版扩散模型，理解 6.pdf 中 “逐步加噪与去噪” 过程 |

#### 学习路径建议

1. 学 6.pdf 中卷积、池化→ 用鱼书 1（入门）7.2 节代码手动实现→ 验证 “输出尺寸计算公式”→ 用《动手学深度学习》11.3 节对比框架实现；
2. 学 6.pdf 中 ResNet→ 结合花书 12.3 节（残差连接）→ 用《动手学深度学习》11.6 节代码复现→ 对比 6.pdf 中 “plain net 与 residual net 的训练误差”；
3. 学 6.pdf 中 GAN、扩散模型→ 用鱼书 1（入门）10.2 节实现 GAN→ 用《动手学深度学习》17.3 节实现扩散模型→ 对比两种生成模型的图像质量。

### （五）Lecture 7：Convolutional Neural Networks - II（7.pdf）

#### 主要内容

1.  **目标检测基础**：指出图像分类仅输出类别，无法满足多目标、定位需求，定义目标检测任务 —— 输入 RGB 图像，输出目标的类别标签与边界框（x,y,width,height），分析挑战（多目标输出、多类型输出、高分辨率图像处理）。

2.  **目标检测评估指标**：讲解交并比（IoU，衡量预测框与真实框重叠度，IoU>0.5 为可接受）、非极大值抑制（NMS，过滤重叠检测框）、平均精度（AP，Precision-Recall 曲线下面积）、均值平均精度（mAP，所有类 AP 的平均值，COCO 数据集采用多 IoU 阈值的 mAP 评估）。

3.  **经典目标检测算法**：

*   **两阶段检测算法**：R-CNN（生成区域提议→CNN 提取特征→SVM 分类 + 边界框回归，速度慢）、Fast R-CNN（共享卷积特征→RoI 池化提取区域特征，提升速度）、Faster R-CNN（引入 RPN 网络生成区域提议，端到端训练，实现实时检测），讲解 RoI 池化与 RoI Align（解决池化对齐问题）的差异。

*   **单阶段检测算法**：YOLO（将图像划分为网格，直接预测边界框与类别概率，速度快，如 YOLOv1 - v8 系列）、SSD（多尺度特征图检测，平衡速度与精度），对比单 / 两阶段算法的优劣（两阶段精度高、单阶段速度快）。

*   **无锚点检测算法**：CornerNet（将目标视为角点对）、CenterNet（将目标视为中心点）、FCOS（全卷积单阶段检测，基于像素回归边界框），解决锚点 - based 方法需预定义锚点的缺陷。

1.  **目标检测数据集与挑战**：介绍 PASCAL VOC、ImageNet、COCO、KITTI、PANDA 等数据集，讨论复杂遮挡、部分可见性等挑战的解决思路（多尺度特征、注意力机制、数据增强、传感器融合等）。

#### 文档核心内容

目标检测任务（边界框、IoU、NMS、mAP）、经典算法（R-CNN、Fast R-CNN、Faster R-CNN、YOLO）、无锚点检测（CenterNet、FCOS）。

#### 对应书籍章节

| 书籍               | 对应章节                                                     | 核心作用                                                     |
| ------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 西瓜书             | 无直接对应章节（侧重传统机器学习，可补充 “多输出模型的评估指标”） | 辅助理解 mAP 与传统分类 “准确率” 指标的差异                  |
| 花书               | 12.3 目标检测；12.5 实例分割（扩展）                         | 1. 理解目标检测 “分类 + 回归” 双任务的损失设计；2. 掌握 “区域 proposal” 的生成逻辑 |
| 鱼书 1（入门）     | 无直接对应章节（侧重基础 CNN，需结合专项资料）               | 辅助理解 “CNN 特征提取与目标检测的关联”，为 Faster R-CNN 的 RPN 网络铺垫 |
| 鱼书 3（框架）     | 7. 模型部署与优化；8. 多任务学习框架                         | 1. 理解目标检测多任务（分类 + 回归）的计算图构建；2. 实现 NMS 算法，验证 7.pdf 中 “过滤重叠框” 的效果 |
| 《动手学深度学习》 | 12. 目标检测（边界框、IoU、Faster R-CNN、YOLO）；13. 语义分割（扩展） | 1. 用 PyTorch 实现 IoU、NMS，验证 7.pdf 中 “评估指标计算”；2. 复现 Faster R-CNN 的 RPN 网络，理解 “端到端检测”；3. 实现 YOLOv3，对比 7.pdf 中 “两阶段与单阶段的速度 - 精度 trade-off” |

#### 学习路径建议

1. 学 7.pdf 中 IoU、mAP→ 用《动手学深度学习》12.2 节代码实现→ 验证不同 IoU 阈值对 mAP 的影响；
2. 学 7.pdf 中 Faster R-CNN→ 结合花书 12.3 节（区域 proposal）→ 用《动手学深度学习》12.5 节代码复现→ 对比 7.pdf 中 “R-CNN、Fast R-CNN、Faster R-CNN 的测试时间”；
3. 学 7.pdf 中 YOLO、CenterNet→ 用《动手学深度学习》12.6 节、12.8 节代码实现→ 对比 “锚点 - based” 与 “无锚点” 检测的精度差异。

### （六）Lecture 9：Recurrent Neural Networks & Graph Neural Networks（9-1.pdf）

#### 主要内容

1.  **序列建模与 RNN**：介绍序列建模应用（一对一：分类；一对多：图像 captioning；多对一：情感分类、动作预测；多对多：机器翻译、视频 captioning），指出 MLP 处理序列的缺陷（效率低、无时序关系建模），讲解 RNN 的结构（通过隐藏状态传递时序信息，$h^{(t)}=\sigma(W_h h^{(t-1)}+W_x x^{(t)}+b)$）、训练方法（随时间反向传播 BPTT，解决时序梯度计算），分析 RNN 的局限（梯度消失 / 爆炸，难以捕捉长时序依赖）。

2.  **LSTM**：详细讲解长短期记忆网络（LSTM），通过细胞状态（存储长期信息）与三个门控（遗忘门：控制丢弃信息；输入门：控制存储新信息；输出门：控制输出信息）解决 RNN 的长依赖问题，推导 LSTM 各模块的计算公式，介绍 LSTM 在手写识别、语音识别、机器翻译等任务中的成功应用。

3.  **图神经网络（GNN）**：介绍图数据的特点（非欧几里得结构、节点连接任意、无固定排序）与应用场景（社交网络、分子结构、交通网络、3D 点云等），定义图的组成（节点、边、全局属性），讲解 GNN 的核心思想 —— 消息传递（节点聚合邻居信息更新自身嵌入），介绍简单 GNN 架构（图独立层、消息传递层）、图卷积（基于拉普拉斯矩阵的谱域卷积，如 ChebNet 用切比雪夫多项式近似，降低计算复杂度）。

4.  **GNN 训练与扩展**：讲解 GNN 的训练方法（基于梯度下降，通过池化实现节点 / 边 / 图级预测），分析 GNN 的挑战（过平滑、动态图处理），介绍 GNN 数据集（ATOM3D、ENZYMES、Reddit、PubMed 等）与评估任务（节点分类、边预测、图分类）。

#### 文档核心内容

RNN/LSTM（序列建模、BPTT、长依赖）、GNN（图数据表示、消息传递、GCN、ChebNet）、应用（语言建模、分子分类）。

#### 对应书籍章节

| 书籍               | 对应章节                                                     | 核心作用                                                     |
| ------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 西瓜书             | 10.3 时序数据建模（传统方法）；11.4 图结构数据学习（基础）   | 1. 理解传统时序模型（如 ARIMA）与 RNN 的差异；2. 掌握图数据的基本统计特征 |
| 花书               | 10.1 循环神经网络；10.4 长短期记忆网络（LSTM）；15.4 图嵌入  | 1. 深入剖析 RNN 的 BPTT 算法，理解梯度消失问题；2. 理解 LSTM 门控机制的数学原理；3. 掌握 GNN 的消息传递框架 |
| 鱼书 1（入门）     | 9. 循环神经网络（RNN、LSTM 实现）；9.4 LSTM 的应用（文本生成） | 1. 手动实现 RNN 的 BPTT，验证 9-1.pdf 中 “随时间反向传播” 的梯度计算；2. 搭建 LSTM 生成文本，理解长依赖捕捉能力 |
| 鱼书 2（NLP）      | 3. 词嵌入；4. RNN 与文本分类；5. LSTM 与序列标注             | 1. 实现词嵌入层，结合 9-1.pdf 中 “序列建模的输入表示”；2. 用 LSTM 进行文本分类（IMDB 数据集），验证 9-1.pdf 中 “RNN 处理序列数据的优势” |
| 鱼书 4（强化学习） | 5. 时序差分学习（TD）；8. 序列决策与 RNN 结合                | 辅助理解 RNN 在强化学习 “时序决策” 中的应用，如 9-1.pdf 中 “视频序列预测” |
| 《动手学深度学习》 | 10. 循环神经网络；11. 门控循环单元（GRU）；19. 图神经网络（GCN、GAT） | 1. 用 PyTorch 实现 LSTM/GRU，对比 9-1.pdf 中 “RNN 与 LSTM 的梯度消失缓解效果”；2. 实战 GCN 在 Cora 数据集上的节点分类，理解 “消息传递”；3. 实现 GAT，对比 9-1.pdf 中 “GCN 与 GAT 的注意力机制差异” |

#### 学习路径建议

1. 学 9-1.pdf 中 RNN、LSTM→ 用鱼书 1（入门）9.2 节代码手动实现 BPTT→ 结合花书 10.4 节推导门控机制→ 用《动手学深度学习》10.3 节对比 LSTM 与 GRU 的性能；
2. 学 9-1.pdf 中 GNN→ 用西瓜书 11.4 节补充图数据基础→ 结合花书 15.4 节（图嵌入）→ 用《动手学深度学习》19.3 节实现 GCN→ 验证 9-1.pdf 中 “节点嵌入的可视化效果”；
3. 学 9-1.pdf 中 GNN 应用（分子分类）→ 用《动手学深度学习》19.5 节代码实现→ 对比 9-1.pdf 中 “不同 GNN 架构的分类精度”。

## 三、完整自学顺序（分阶段）

#### 核心目标

掌握数学基础（线性代数、概率统计）、传统机器学习理论与代码实现。

#### 学习内容

1. **数学基础**：复习线性代数（矩阵运算、特征值分解）、概率统计（期望、方差、贝叶斯公式）；
2. **传统机器学习**：
   - 西瓜书第 3 章（线性模型）、第 6 章（SVM）、第 9 章（K-means）、第 10 章（PCA）；
   - 《动手学深度学习》第 3 章（线性回归）、第 4 章（Softmax）、第 10 章（K-means）；
   - 鱼书 1（入门）第 3 章（神经网络数学基础）、第 4 章（梯度下降）；
3. **实践任务**：用线性回归预测房价（Ames 数据集）、用 SVM 分类鸢尾花、用 PCA 降维 MNIST 并可视化。

#### 核心目标

掌握 DNN、CNN 的理论与实现，理解反向传播、优化算法等核心技术。

#### 学习内容

1. **DNN 基础**：
   - 花书第 6 章（深度前馈网络）、第 7 章（正则化）、第 8 章（优化算法）；
   - 鱼书 1（入门）第 5 章（BP 算法）、第 6 章（权重初始化、批归一化）；
   - 《动手学深度学习》第 5 章（MLP）、第 7 章（优化算法）、第 8 章（批归一化）；
2. **CNN 基础**：
   - 花书第 12 章（CNN）；
   - 鱼书 1（入门）第 7 章（卷积、池化实现）；
   - 《动手学深度学习》第 11 章（CNN 基础架构）；
3. **实践任务**：搭建 5 层 MLP 分类 MNIST（精度≥97%）、实现 LeNet 分类 Fashion-MNIST、复现 AlexNet 分类 CIFAR-10。

#### 核心目标

掌握 RNN/LSTM、GNN、目标检测、生成模型的理论与工程实现。

#### 学习内容

1. **序列建模（RNN/LSTM）**：
   - 花书第 10 章（RNN、LSTM）；
   - 鱼书 1（入门）第 9 章（RNN 实现）、鱼书 2（NLP）第 3-5 章（词嵌入、文本分类）；
   - 《动手学深度学习》第 10 章（RNN/LSTM）；
2. **图模型（GNN）**：
   - 花书第 15 章（图嵌入）；
   - 西瓜书第 11 章（图数据学习）；
   - 《动手学深度学习》第 19 章（GCN、GAT）；
3. **目标检测**：
   - 花书第 12 章（目标检测）；
   - 《动手学深度学习》第 12 章（Faster R-CNN、YOLO）；
   - 鱼书 3（框架）第 8 章（多任务学习）；
4. **生成模型**：
   - 花书第 12 章（GAN）、第 15 章（扩散模型）；
   - 鱼书 1（入门）第 10 章（GAN 实现）；
   - 《动手学深度学习》第 16 章（GAN）、第 17 章（扩散模型）；
5. **实践任务**：用 LSTM 生成古诗、GCN 分类 Cora 论文、YOLOv3 检测 COCO 子集、扩散模型生成图像。

#### 核心目标

结合课程文档应用场景，综合运用模型解决实际问题。

#### 学习内容

1. **场景适配**：
   - 2-1.pdf（MEG 脑成像）：用 PCA 降维 + MLP 分类；
   - 6.pdf（图像生成）：用扩散模型实现文本到图像生成；
   - 7.pdf（目标检测）：用 YOLOv3 实现工业质检目标检测；
   - 9-1.pdf（分子分类）：用 GCN 预测分子属性；
2. **框架深化**：
   - 鱼书 3（框架）：实现简易自动求导框架，复现 CNN 反向传播；
   - 鱼书 4（强化学习）：用 DQN 结合 CNN 实现 Atari 游戏通关；
3. **实践任务**：选择 1 个场景（如 “脑成像数据分类”），完成从数据预处理（PCA）、模型搭建（MLP）、训练优化（Adam、批归一化）到评估（准确率、F1）的完整流程。

### （一）整体逻辑：从基础理论到应用模型，兼顾课程顺序与知识依赖

1.  **第一阶段：数学基础与传统机器学习（支撑后续深度学习）**

*   **内容**：线性代数（矩阵运算、特征值 / 特征向量，对应花书第 2 章）、概率论与数理统计（极大似然估计、概率分布，对应花书第 3 章）、西瓜书第 3 章（线性模型：线性回归、逻辑回归）、第 6 章（支持向量机）、第 9 章（聚类：K-means）。

*   **原因**：线性模型是深度学习的基础（如神经网络的全连接层本质是线性变换 + 激活），SVM 的核思想为 CNN 的卷积操作提供借鉴，聚类为无监督特征学习铺垫。

1.  **第二阶段：特征工程（课程 Lecture 2、4）**

*   **内容**：文档 7（Lecture 2 基础部分：PCA、传统特征检测如 Harris、SIFT）→文档 2（Lecture 4：线性回归、逻辑回归、SVM、Softmax、K-means）→文档 1（Lecture 2 Supplement：学习型特征如 LIFT、SuperPoint、LF-Net）。

*   **原因**：先掌握传统手工特征提取（PCA 降维、角点检测、SIFT 描述子），理解特征工程的核心需求；再学习基于传统机器学习的特征应用（如用 SVM 分类 SIFT 特征）；最后过渡到学习型特征，为深度学习特征提取衔接。

1.  **第三阶段：深度学习基础（课程 Lecture 5）**

*   **内容**：花书第 6 章（深度前馈网络：感知机、激活函数、反向传播）→花书第 7 章（正则化：Dropout、L1/L2）、第 8 章（优化：梯度下降、动量、Adam）→文档 3（Lecture 5：DNN 训练技术如批归一化、参数初始化、超参数调优）。

*   **原因**：先掌握神经网络的基础结构与训练核心（反向传播），再解决训练中的关键问题（过拟合、梯度消失 / 爆炸、优化效率），最后结合课程中的工程实践技术（批归一化、初始化），形成完整的 DNN 知识体系。

1.  **第四阶段：卷积神经网络（课程 Lecture 6、7）**

*   **内容**：花书第 12 章 12.1 节（CNN 基础：卷积、池化、经典架构如 AlexNet、VGG）→文档 4（Lecture 6：CNN 架构细节、GAN、扩散模型）→文档 5（Lecture 7：目标检测：R-CNN 系列、YOLO、无锚点算法）。

*   **原因**：CNN 是视觉任务的核心模型，先理解基础构建块与经典架构；再扩展到生成模型（GAN、扩散），掌握 CNN 的生成能力；最后聚焦 CNN 的重要应用 —— 目标检测，从两阶段到单阶段、无锚点，逐步深入复杂任务。

1.  **第五阶段：序列与图模型（课程 Lecture 9）**

*   **内容**：花书第 10 章（RNN、LSTM）→文档 6（Lecture 9：RNN 训练与应用、GNN 基础：消息传递、图卷积）→GNN 专项资料（如 ChebNet、GCN）。

*   **原因**：RNN 处理时序数据，LSTM 解决长依赖问题，是序列任务的基础；GNN 处理非欧数据，是传统深度学习的重要扩展，二者分别覆盖时序与图结构这两类非网格数据，完善深度学习知识体系。

### （二）关键衔接点说明

*   **传统机器学习与深度学习**：线性回归的梯度下降是 DNN 优化的基础，SVM 的核技巧与 CNN 的局部特征提取逻辑相通，需在学习 DNN 前确保传统方法的梯度计算、优化思想掌握扎实。

*   **特征工程与 CNN**：传统特征（如 SIFT）的尺度 / 旋转不变性需求，推动 CNN 的参数共享、多尺度卷积设计，学习时需对比手工特征与 CNN 自动特征提取的差异与联系。

*   **DNN 与 CNN/GNN**：DNN 的反向传播、正则化、优化技术可直接迁移到 CNN 与 GNN，学习时需重点关注 CNN 的卷积 / 池化、GNN 的消息传递等特有模块，理解其如何适配不同数据结构（网格、图）。

## 四、书籍与文档衔接注意事项

1. **避免重复学习**：同一知识点（如梯度下降）在多本书籍中出现时，优先按 “鱼书 1（通俗解释）→ 花书（理论推导）→ 《动手学深度学习》（代码实现）” 的顺序，聚焦差异点而非重复内容；
2. **文档优先**：所有书籍学习需围绕 8 份核心文档的知识点展开，例如学鱼书 2（NLP）时，重点衔接 9-1.pdf 中 “RNN 序列建模”，而非全面覆盖 NLP 所有内容；
3. **实践导向**：每学完文档一个章节，需配套至少 1 个代码实践（如学 5.pdf 反向传播后，用鱼书 1 手动实现 +《动手学深度学习》框架验证），确保理论落地；
4. **专项补充**：鱼书 3（框架）、鱼书 4（强化学习）作为扩展，可根据兴趣选择深入，重点优先保证 DNN、CNN、RNN、GNN 等核心模型的学习。

# 参考书籍章节与课程PPT对应表

以下表格以6本核心参考书籍为索引，系统梳理各章节与课程8份PPT（Lecture 2至Lecture 9）的对应关系，覆盖“理论奠基+实践落地+专项深化”三层知识体系，为自学过程中的“书籍-课件”联动学习提供清晰指引。

## 一、《机器学习》（西瓜书）章节-PPT对应表

| 西瓜书章节              | 对应课程PPT          | 核心对应内容                                                 |
| ----------------------- | -------------------- | ------------------------------------------------------------ |
| 3.2 线性回归            | Lecture 4（4.pdf）   | 线性回归的闭式解推导、梯度下降优化逻辑，匹配PPT中“线性模型建模”章节 |
| 5.3 神经网络            | Lecture 5（5.pdf）   | 神经网络基础架构（感知机、层级连接），为PPT中DNN结构讲解提供理论铺垫 |
| 6.2 支持向量机          | Lecture 4（4.pdf）   | SVM最大间隔原理、核技巧，对应PPT中“二分类模型”核心知识点     |
| 7.1 模型评估与选择      | Lecture 5（5.pdf）   | 正则化（L1、L2）原理，匹配PPT中“模型训练正则化技术”章节      |
| 9.1 K均值聚类           | Lecture 4（4.pdf）   | K-means聚类逻辑、中心更新规则，对应PPT中“无监督学习-聚类”内容 |
| 10.1 主成分分析（PCA）  | Lecture 2（2-1.pdf） | PCA数学原理（协方差矩阵、特征值分解），匹配PPT中“高维数据降维”章节 |
| 10.3 时序数据建模       | Lecture 9（9-1.pdf） | 传统时序模型基础，与PPT中“RNN序列建模”形成方法对比           |
| 11.1 特征选择与稀疏学习 | Lecture 2（2-1.pdf） | 传统特征筛选方法，辅助理解PPT中“学习型特征提取”的演进逻辑    |
| 11.4 图结构数据学习     | Lecture 9（9-1.pdf） | 图数据基本统计特征，为PPT中“GNN图数据表示”提供基础概念       |

## 二、《深度学习》（花书）章节-PPT对应表

| 花书章节                    | 对应课程PPT                            | 核心对应内容                                                 |
| --------------------------- | -------------------------------------- | ------------------------------------------------------------ |
| 5.1 线性模型                | Lecture 4（4.pdf）                     | 线性模型的概率解释，深化PPT中“逻辑回归、Softmax”的理论深度   |
| 5.6 优化算法                | Lecture 4（4.pdf）、Lecture 5（5.pdf） | 动量、RMSProp等梯度下降变种，对应PPT中“动态学习率”“优化算法”章节 |
| 6.1 深度前馈网络            | Lecture 5（5.pdf）                     | DNN层级结构、激活函数作用，匹配PPT中“Deep Neural Networks基础”内容 |
| 6.5 反向传播                | Lecture 5（5.pdf）                     | 反向传播数学推导（链式法则），对应PPT中“BP算法原理”核心知识点 |
| 7.1 正则化                  | Lecture 5（5.pdf）                     | 批归一化、Dropout理论依据，匹配PPT中“训练技术-正则化”章节    |
| 8.1 参数更新算法            | Lecture 5（5.pdf）                     | Adam等优化算法收敛性分析，对应PPT中“优化算法性能对比”内容    |
| 10.1 循环神经网络           | Lecture 9（9-1.pdf）                   | RNN结构、BPTT算法，匹配PPT中“序列建模-RNN”章节               |
| 10.4 长短期记忆网络（LSTM） | Lecture 9（9-1.pdf）                   | LSTM门控机制数学原理，对应PPT中“长依赖捕捉-LSTM”核心内容     |
| 11.3 软max回归              | Lecture 4（4.pdf）                     | Softmax多分类概率建模，匹配PPT中“多分类模型”章节             |
| 12.1 卷积神经网络           | Lecture 6（6.pdf）                     | 卷积运算数学本质（局部连接、参数共享），对应PPT中“CNN基础”内容 |
| 12.3 目标检测               | Lecture 7（7.pdf）                     | 目标检测“分类+回归”双任务损失设计，匹配PPT中“目标检测基础”章节 |
| 12.4 生成对抗网络           | Lecture 6（6.pdf）                     | GAN对抗训练博弈论基础，对应PPT中“生成模型-GAN”章节           |
| 15.2 自编码器               | Lecture 2（2-1.pdf）                   | 非线性降维原理，对比PPT中“PCA线性降维”的差异                 |
| 15.4 图嵌入                 | Lecture 9（9-1.pdf）                   | GNN消息传递框架，对应PPT中“GNN图数据表示”章节                |
| 15.5 深度生成模型           | Lecture 6（6.pdf）                     | 扩散模型非平衡热力学原理，对应PPT中“生成模型-扩散模型”内容   |

## 三、《深度学习入门：基于Python的理论与实现》（鱼书1）章节-PPT对应表

| 鱼书1章节             | 对应课程PPT                            | 核心对应内容                                                 |
| --------------------- | -------------------------------------- | ------------------------------------------------------------ |
| 3. 神经网络的数学基础 | Lecture 4（4.pdf）、Lecture 5（5.pdf） | 梯度计算、矩阵运算，为PPT中“线性回归梯度下降”“DNN数学基础”提供实践铺垫 |
| 4. 神经网络的学习     | Lecture 4（4.pdf）、Lecture 5（5.pdf） | 梯度下降手动实现、学习率影响，对应PPT中“优化算法实践”章节    |
| 5. 误差反向传播       | Lecture 5（5.pdf）                     | 2层DNN反向传播手动推导，验证PPT中“BP算法链式法则应用”        |
| 6. 与学习相关的技巧   | Lecture 5（5.pdf）                     | 权重初始化、批归一化实现，匹配PPT中“训练技术-批归一化”内容   |
| 7. 卷积神经网络       | Lecture 6（6.pdf）                     | 卷积层、池化层手动实现，验证PPT中“CNN参数共享减少参数量”的效果 |
| 8. 深度学习的应用     | Lecture 6（6.pdf）                     | 简单CNN（LeNet）搭建，对比PPT中AlexNet的架构创新             |
| 9. 循环神经网络       | Lecture 9（9-1.pdf）                   | RNN、LSTM实现，BPTT梯度计算，对应PPT中“RNN序列建模”章节      |
| 9.4 LSTM的应用        | Lecture 9（9-1.pdf）                   | LSTM文本生成实践，理解PPT中“长依赖捕捉”的实际效果            |
| 10. 生成对抗网络      | Lecture 6（6.pdf）                     | GAN生成MNIST图像，理解PPT中“对抗训练逻辑”                    |

## 四、《深度学习进阶：自然语言处理》（鱼书2）章节-PPT对应表

| 鱼书2章节          | 对应课程PPT          | 核心对应内容                                                 |
| ------------------ | -------------------- | ------------------------------------------------------------ |
| 3. 词嵌入          | Lecture 9（9-1.pdf） | 词向量表示（共现矩阵、PPMI、SVD），对应PPT中“序列建模输入表示”章节 |
| 4. RNN与文本分类   | Lecture 9（9-1.pdf） | RNN文本分类实现（IMDB数据集），验证PPT中“RNN处理序列数据优势” |
| 5. LSTM与序列标注  | Lecture 9（9-1.pdf） | LSTM序列标注实践，匹配PPT中“LSTM长依赖捕捉”核心内容          |
| 7. 基于RNN生成文本 | Lecture 9（9-1.pdf） | RNN语言模型文本生成，对应PPT中“序列生成应用”章节             |

## 五、《深度学习进阶：自制深度学习框架》（鱼书3）章节-PPT对应表

| 鱼书3章节           | 对应课程PPT                              | 核心对应内容                                                 |
| ------------------- | ---------------------------------------- | ------------------------------------------------------------ |
| 1. 框架核心组件     | Lecture 5（5.pdf）                       | 计算图、张量等框架基础，理解PPT中“DNN训练依赖的底层组件”     |
| 2. 张量运算         | Lecture 4（4.pdf）、Lecture 6（6.pdf）   | 矩阵乘法、卷积等张量操作，对应PPT中“线性模型运算”“CNN卷积运算” |
| 3. 自动求导机制     | Lecture 2（2-1.pdf）、Lecture 5（5.pdf） | 自动求导实现，理解PPT中“学习型特征模型反向传播”“DNN BP算法”的工程依赖 |
| 5. 优化器实现       | Lecture 5（5.pdf）                       | SGD、Adam优化器手动实现，验证PPT中“动态学习率效果”           |
| 6. 批处理与并行计算 | Lecture 5（5.pdf）                       | 批处理实现，匹配PPT中“高-performance computing算力需求”章节  |
| 8. 多任务学习框架   | Lecture 7（7.pdf）                       | 多任务计算图构建，对应PPT中“目标检测分类+回归双任务”内容     |

## 六、《深度学习进阶：强化学习》（鱼书4）章节-PPT对应表

| 鱼书4章节              | 对应课程PPT                              | 核心对应内容                                                |
| ---------------------- | ---------------------------------------- | ----------------------------------------------------------- |
| 5. 时序差分学习（TD）  | Lecture 9（9-1.pdf）                     | 时序决策价值估计，辅助理解PPT中“RNN时序建模”的时序依赖逻辑  |
| 6. 策略梯度            | Lecture 6（6.pdf）                       | 策略优化方法，关联PPT中“GAN生成器策略优化”的思路            |
| 7. 深度强化学习（DQN） | Lecture 6（6.pdf）、Lecture 9（9-1.pdf） | DQN结合CNN实现，对应PPT中“CNN特征提取+序列决策”的跨领域应用 |
| 8. 序列决策与RNN结合   | Lecture 9（9-1.pdf）                     | RNN在强化学习时序决策中的应用，匹配PPT中“视频序列预测”场景  |

## 七、《动手学深度学习》（D2L）章节-PPT对应表

| D2L章节          | 对应课程PPT                              | 核心对应内容                                                 |
| ---------------- | ---------------------------------------- | ------------------------------------------------------------ |
| 3.1 线性回归     | Lecture 2（2-1.pdf）、Lecture 4（4.pdf） | PCA数学基础（矩阵运算）、线性回归实现，对应PPT中“降维”“线性模型”章节 |
| 4. Softmax回归   | Lecture 4（4.pdf）                       | Softmax多分类实现，验证PPT中“多分类模型交叉熵损失”           |
| 5. 多层感知机    | Lecture 5（5.pdf）                       | MLP搭建与训练，匹配PPT中“DNN基础架构”内容                    |
| 7. 优化算法      | Lecture 5（5.pdf）                       | Adam、RMSProp实战，对比PPT中“优化算法收敛速度”               |
| 8. 批量归一化    | Lecture 5（5.pdf）                       | 批归一化层实现，验证PPT中“缓解梯度消失”效果                  |
| 11. 卷积神经网络 | Lecture 6（6.pdf）                       | AlexNet、VGG、ResNet复现，对比PPT中“经典CNN架构准确率”       |
| 12. 目标检测     | Lecture 7（7.pdf）                       | Faster R-CNN、YOLO实现，对应PPT中“两阶段与单阶段检测”章节    |
| 16. 生成对抗网络 | Lecture 6（6.pdf）                       | DCGAN、StyleGAN实战，验证PPT中“GAN生成高质量图像”            |
| 17. 扩散模型     | Lecture 6（6.pdf）                       | 简化版扩散模型实现，理解PPT中“逐步加噪与去噪”过程            |
| 19. 图神经网络   | Lecture 9（9-1.pdf）                     | GCN、GAT实现，对比PPT中“图模型注意力机制差异”                |

使用说明：1. 表格中“核心对应内容”已标注关键衔接点，学习时可优先聚焦这些知识点；2. 若同一章节对应多个PPT，需结合PPT场景差异调整学习重点（如鱼书3的“自动求导”在Lecture 2侧重特征模型，在Lecture 5侧重DNN）；3. 可结合之前的“自学顺序”，按阶段匹配书籍章节与PPT进行系统性学习。